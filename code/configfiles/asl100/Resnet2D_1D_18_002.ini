[training]
batch_size = 2
update_per_step = 16
max_epoch = 200
early_stopping = {'metric' : ('val','loss'), 'mode': 'min', 'patience': 50, 'min_delta': 0.01}

[optimizer]
eps = 1e-3
backbone_init_lr = 1e-5
backbone_weight_decay = 1e-4
classifier_init_lr = 1e-3
classifier_weight_decay = 1e-7

[scheduler] 
tmax = 100
eta_min = 1e-5

[data]
num_frames = 32 
frame_size = 224


; based on Restnet2D_1D_18_001 and S3D_007


; 001 took forever to train
; had to drop batch size to 2 (increased batch accum to maintain equivalent batch size)
; still takes up loads of GPU memory

; and actually just took forever to train
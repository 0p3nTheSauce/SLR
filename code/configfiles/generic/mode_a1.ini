[training]
batch_size = 8
update_per_step = 1
max_epoch = 200

[optimizer]
eps = 1e-4
backbone_init_lr = 1e-4
backbone_weight_decay = 1e-3
classifier_init_lr = 1e-3
classifier_weight_decay = 1e-4

[model_params]
drop_p = 0.5

[scheduler] 
type = 'CosineAnnealingLR'
start_factor = 0.1
end_factor = 1.0
warmup_epochs = 10
tmax = 200
eta_min = 0

[data]
num_frames = 32
frame_size = 224

[early_stopping]
metric = ('val', 'loss')
mode = 'min'
patience = 50
min_delta = 0.01

; same as mode_a, but with warm ups
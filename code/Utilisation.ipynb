{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model, avail_models, norm_vals\n",
    "from video_dataset import get_data_loader\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, ProfilerActivity, record_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653857b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48259c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avail_models: \n",
      "S3D, R3D_18, R(2+1)D_18, Swin3D_T, Swin3D_S, Swin3D_B, MViTv2_S, MViTv1_B\n"
     ]
    }
   ],
   "source": [
    "print(\"avail_models: \")\n",
    "avail_m = avail_models()\n",
    "print(', '.join(avail_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174d2b9",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e92d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 16, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "fs = 224 #frame size\n",
    "nf = 16 #num frames\n",
    "\n",
    "nvals = norm_vals(avail_m[0]) #normalisation won't make a difference in this case\n",
    "# testloader = get_data_loader(\n",
    "#     mean=nvals['mean'],\n",
    "#     std=nvals['std'],\n",
    "#     frame_size=fs,\n",
    "#     num_frames=nf,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4272e",
   "metadata": {},
   "source": [
    "## First test on S3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2006df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 100 #num classes\n",
    "dropout = 0.0 #no dropout\n",
    "model = get_model(avail_m[0], nc, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b24490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3D_basic(\n",
      "  (backbone): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): TemporalSeparableConv(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(64, 64, kernel_size=(7, 1, 1), stride=(2, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "      (2): Conv3dNormActivation(\n",
      "        (0): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): TemporalSeparableConv(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(64, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "      (5): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(96, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(32, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(32, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(96, 96, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=1, ceil_mode=False)\n",
      "      (8): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(96, 208, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(208, 208, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(16, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(48, 48, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(112, 224, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(224, 224, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(144, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(144, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(288, 288, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
      "      (14): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): SepInceptionBlock3D(\n",
      "        (branch0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(192, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(384, 384, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): TemporalSeparableConv(\n",
      "            (0): Conv3dNormActivation(\n",
      "              (0): Conv3d(48, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv3dNormActivation(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "              (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (branch3): Sequential(\n",
      "          (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AvgPool3d(kernel_size=(2, 7, 7), stride=1, padding=0)\n",
      "  )\n",
      "  (features): Sequential(\n",
      "    (0): TemporalSeparableConv(\n",
      "      (0): Conv3dNormActivation(\n",
      "        (0): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv3dNormActivation(\n",
      "        (0): Conv3d(64, 64, kernel_size=(7, 1, 1), stride=(2, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "    (2): Conv3dNormActivation(\n",
      "      (0): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): TemporalSeparableConv(\n",
      "      (0): Conv3dNormActivation(\n",
      "        (0): Conv3d(64, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv3dNormActivation(\n",
      "        (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "    (5): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(96, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(32, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(96, 96, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=1, ceil_mode=False)\n",
      "    (8): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(96, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(96, 208, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(208, 208, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(208, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(16, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(16, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(48, 48, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(112, 224, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(224, 224, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(224, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(24, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(24, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(112, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(144, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(144, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(288, 288, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(288, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(64, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 0, 0), dilation=1, ceil_mode=False)\n",
      "    (14): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(832, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(160, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(160, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(320, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(32, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(32, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): SepInceptionBlock3D(\n",
      "      (branch0): Conv3dNormActivation(\n",
      "        (0): Conv3d(832, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(192, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(192, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(384, 384, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(384, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(48, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): TemporalSeparableConv(\n",
      "          (0): Conv3dNormActivation(\n",
      "            (0): Conv3d(48, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv3dNormActivation(\n",
      "            (0): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=(3, 3, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv3dNormActivation(\n",
      "          (0): Conv3d(832, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(128, eps=0.001, momentum=0.001, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool3d(kernel_size=(2, 7, 7), stride=1, padding=0)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.0, inplace=False)\n",
      "    (1): Conv3d(1024, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1c4a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1102 16:11:35.186217439 kineto_shim.cpp:415] Adding profiling metadata requires using torch.profiler with Kineto support (USE_KINETO=1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profile(activities\u001b[38;5;241m=\u001b[39mactivities, record_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m record_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(prof\u001b[38;5;241m.\u001b[39mkey_averages()\u001b[38;5;241m.\u001b[39mtable(sort_by\u001b[38;5;241m=\u001b[39msort_by_keyword, row_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Code/SLR/code/models/pytorch_s3d.py:46\u001b[0m, in \u001b[0;36mS3D_basic.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 46\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     48\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wlasl/lib/python3.10/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU]\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    activities += [ProfilerActivity.CUDA]\n",
    "elif torch.xpu.is_available():\n",
    "    device = \"xpu\"\n",
    "    activities += [ProfilerActivity.XPU]\n",
    "else:\n",
    "    print(\n",
    "        \"Neither CUDA nor XPU devices are available to demonstrate profiling on acceleration devices\"\n",
    "    )\n",
    "    import sys\n",
    "\n",
    "    sys.exit(0)\n",
    "\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "\n",
    "model = model.to(device)\n",
    "inputs = video.to(device)\n",
    "\n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb300731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlasl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

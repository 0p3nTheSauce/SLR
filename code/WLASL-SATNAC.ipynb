{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e017a9d2",
   "metadata": {},
   "source": [
    "# Comparing 3D CNN, and Vision Transformer feature extractors for Isolated Sign Language Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061ac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import test\n",
    "import configs\n",
    "from torchvision.transforms import v2\n",
    "from video_dataset import VideoDataset\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from models import pytorch_mvit, pytorch_r3d, pytorch_s3d, pytorch_swin3d\n",
    "import json\n",
    "import utils\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  \n",
    "set_seed()\n",
    "\n",
    "with open('wlasl_implemented_info.json', 'r') as f:\n",
    "  imp_info = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac83f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asl100', 'asl300']\n",
      "dict_keys(['MViT_V1_B', 'MViT_V2_S', 'Swin3D_B', 'Swin3D_S', 'Swin3D_T', 'Resnet2D_1D_18', 'Resnet3D_18', 'S3D'])\n"
     ]
    }
   ],
   "source": [
    "print(imp_info['splits'])\n",
    "print(imp_info['models'].keys())\n",
    "model_info = imp_info['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec76f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'asl100'\n",
    "root = Path('../data/WLASL/WLASL2000')\n",
    "labels = Path(f'./preprocessed/labels/{split}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6112d9",
   "metadata": {},
   "source": [
    "## Main results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6ccdc",
   "metadata": {},
   "source": [
    "### load testing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225f07d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "asl100 : {\n",
      "Resnet3D_18 : ['004', '005']\n",
      "Resnet2D_1D_18 : ['004', '006']\n",
      "S3D : ['010', '012']\n",
      "MViT_V1_B : ['000']\n",
      "MViT_V2_S : ['004']\n",
      "Swin3D_B : ['002']\n",
      "Swin3D_S : ['002']\n",
      "Swin3D_T : ['002']\n",
      "}\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('results/wlasl_runs_to_test.json', 'r') as f:\n",
    "    to_test = json.load(f)\n",
    "\n",
    "utils.print_dict(to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8628f8",
   "metadata": {},
   "source": [
    "### test experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9761cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Path('results/')\n",
    "# test.test_all(\n",
    "#     runs_dict = to_test,\n",
    "#     test_last = True, #verify that best weights are working\n",
    "#     plot = True, \n",
    "#     disp = True, #lets see some graphs\n",
    "#     res_output = output / 'wlasl_same_setup.json',\n",
    "#     skip_done = False, #rerun all the tests the first time \n",
    "#     err_output = output / 'wlasl_same_setup_errors.json'\n",
    "# )\n",
    "\n",
    "\n",
    "#cleared cell outputs because of size\n",
    "#commented out to prevent re-running everything by accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d784c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/wlasl_same_setup.json', 'r') as f:\n",
    "  result_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa32a67",
   "metadata": {},
   "source": [
    "## Comparing all with 16 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46950867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "asl100 : {\n",
      "Resnet3D_18 : ['005']\n",
      "Resnet2D_1D_18 : ['006']\n",
      "S3D : ['012']\n",
      "MViT_V1_B : ['000']\n",
      "MViT_V2_S : ['004']\n",
      "Swin3D_B : ['002']\n",
      "Swin3D_S : ['002']\n",
      "Swin3D_T : ['002']\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "['asl100']\n",
      "[[('Resnet3D_18', '005'), ('Resnet2D_1D_18', '006'), ('S3D', '012'), ('MViT_V1_B', '000'), ('MViT_V2_S', '004'), ('Swin3D_B', '002'), ('Swin3D_S', '002'), ('Swin3D_T', '002')]]\n",
      "{\n",
      "asl100 : {\n",
      "Resnet3D_18 : {\n",
      "exp : 005\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.45699999999999996\n",
      "top5 : 0.7583333333333333\n",
      "top10 : 0.8658333333333332\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "Resnet2D_1D_18 : {\n",
      "exp : 006\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.5025\n",
      "top5 : 0.8204999999999998\n",
      "top10 : 0.8913333333333333\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "S3D : {\n",
      "exp : 012\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.29866666666666664\n",
      "top5 : 0.5998333333333333\n",
      "top10 : 0.7313333333333333\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "MViT_V1_B : {\n",
      "exp : 000\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.6656666666666666\n",
      "top5 : 0.8783333333333333\n",
      "top10 : 0.93\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "MViT_V2_S : {\n",
      "exp : 004\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.6798333333333332\n",
      "top5 : 0.8908333333333333\n",
      "top10 : 0.9383333333333335\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "Swin3D_B : {\n",
      "exp : 002\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.5589999999999999\n",
      "top5 : 0.8521666666666667\n",
      "top10 : 0.9458333333333333\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "Swin3D_S : {\n",
      "exp : 002\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.46366666666666667\n",
      "top5 : 0.7476666666666667\n",
      "top10 : 0.8846666666666665\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "Swin3D_T : {\n",
      "exp : 002\n",
      "top_k_average_per_class_acc : {\n",
      "top1 : 0.4645\n",
      "top5 : 0.7676666666666666\n",
      "top10 : 0.8838333333333332\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "}\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('results/wlasl_satnac_16_only.json', 'r') as f:\n",
    "  satnac_16_only = json.load(f)\n",
    "utils.print_dict(satnac_16_only)\n",
    "summary = test.summarise(\n",
    "    result_dict, \n",
    "    to_summarise = satnac_16_only,\n",
    "    metric = 'top_k_average_per_class_acc'\n",
    ")\n",
    "# with open('results/wlasl_satnac_16_only_summary.json', 'w') as f:\n",
    "#     json.dump(summary, f, indent=4)\n",
    "utils.print_dict(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222ebd6",
   "metadata": {},
   "source": [
    "## Comparing 32 frames to 16 frames for 3D CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f60d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 frame experiments:\n",
      "[('Resnet3D_18', '005'), ('Resnet2D_1D_18', '006'), ('S3D', '012')]\n",
      "32 frame experiments:\n",
      "[('Resnet3D_18', '004'), ('Resnet2D_1D_18', '004'), ('S3D', '010')]\n"
     ]
    }
   ],
   "source": [
    "#summarise uses architectures as keys, so we should rather seperately summarise,\n",
    "#into two dictionaries (later tables) for 16 and 32 frames\n",
    "splits = ['asl100']\n",
    "archs = ['Resnet3D_18', 'Resnet2D_1D_18', 'S3D']\n",
    "c3d16s = [\"005\", '006', '012']\n",
    "c3d32s = [\"004\", \"004\", \"010\"]\n",
    "\n",
    "model_exps_16f = []\n",
    "model_exps_32f = []\n",
    "\n",
    "for arch, c16, c32 in zip(archs, c3d16s, c3d32s):\n",
    "    model_exps_16f.append((arch, c16))\n",
    "    model_exps_32f.append((arch, c32))\n",
    "\n",
    "print(\"16 frame experiments:\")\n",
    "print(model_exps_16f)\n",
    "print(\"32 frame experiments:\")\n",
    "print(model_exps_32f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88707f",
   "metadata": {},
   "source": [
    "### 16 frame summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06166abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asl100']\n",
      "[[('Resnet3D_18', '005'), ('Resnet2D_1D_18', '006'), ('S3D', '012')]]\n"
     ]
    }
   ],
   "source": [
    "sum16 = test.summarise(\n",
    "    result_dict,\n",
    "    splits=splits,\n",
    "    model_exps = [model_exps_16f],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95baf82",
   "metadata": {},
   "source": [
    "### 32 frame summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb038d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asl100']\n",
      "[[('Resnet3D_18', '004'), ('Resnet2D_1D_18', '004'), ('S3D', '010')]]\n"
     ]
    }
   ],
   "source": [
    "sum32 = test.summarise(\n",
    "    result_dict,\n",
    "    splits=splits,\n",
    "    model_exps = [model_exps_32f],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb90774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\begin{center} \n",
      "\\caption{16 frame 3D CNN results on WLASL100}\n",
      "\\label{tab:wlasl_16f}\n",
      "\\begin{tabular}{|l|ccc|}\n",
      "\\hline\\textbf{Model} & \\textbf{Acc@1} & \\textbf{Acc@5} & \\textbf{Acc@10} \\\\ \n",
      "\\hline \n",
      "Resnet3D\\_18 & 45.7 & 75.83 & 86.58 \\\\ \n",
      "Resnet2D\\_1D\\_18 & 50.25 & 82.05 & 89.13 \\\\ \n",
      "S3D & 29.87 & 59.98 & 73.13 \\\\ \n",
      "\\hline \n",
      "\\multicolumn{4}{l}{All models use 16 frames as input.} \\\\ \n",
      "\\end{tabular} \n",
      "\\end{center} \n",
      "\\end{table} \n",
      "\n",
      "\n",
      "%%%%%%%%%%\n",
      "\n",
      "\\begin{table}[t]\n",
      "\\begin{center} \n",
      "\\caption{32 frame 3D CNN results on WLASL100}\n",
      "\\label{tab:wlasl_32f}\n",
      "\\begin{tabular}{|l|ccc|}\n",
      "\\hline\\textbf{Model} & \\textbf{Acc@1} & \\textbf{Acc@5} & \\textbf{Acc@10} \\\\ \n",
      "\\hline \n",
      "Resnet3D\\_18 & 53.43 & 82.0 & 89.5 \\\\ \n",
      "Resnet2D\\_1D\\_18 & 51.32 & 76.35 & 85.02 \\\\ \n",
      "S3D & 41.22 & 68.0 & 78.58 \\\\ \n",
      "\\hline \n",
      "\\multicolumn{4}{l}{All models use 32 frames as input.} \\\\ \n",
      "\\end{tabular} \n",
      "\\end{center} \n",
      "\\end{table} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tables import gen_single_split_table\n",
    "\n",
    "print(gen_single_split_table(\n",
    "    split_dict=sum16['asl100'],\n",
    "    caption='16 frame 3D CNN results on WLASL100', label='tab:wlasl_16f',\n",
    "    footnotes=['All models use 16 frames as input.']\n",
    ")\n",
    ")\n",
    "\n",
    "print()\n",
    "print('%'*10)\n",
    "print()\n",
    "\n",
    "print(gen_single_split_table(\n",
    "    split_dict=sum32['asl100'],\n",
    "    caption='32 frame 3D CNN results on WLASL100', label='tab:wlasl_32f',\n",
    "    footnotes=['All models use 32 frames as input.']\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d6f99",
   "metadata": {},
   "source": [
    "# now we can create a differences table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d20375",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_compare_table\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgen_compare_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum16\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masl100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum32\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masl100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mComparison of 16 and 32 frame 3D CNN results on WLASL100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtab:wlasl_16f_vs_32f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfootnotes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m32 - 16 frame difference\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAll models use 16 or 32 frames as input respectively.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m       \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/ExtraStorage/SLR/code/tables.py:66\u001b[0m, in \u001b[0;36mgen_compare_table\u001b[0;34m(res_dict1, res_dict2, met_key, split, caption, label, footnotes, precision)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgen_compare_table\u001b[39m(res_dict1:\u001b[38;5;28mdict\u001b[39m, res_dict2:\u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m     59\u001b[0m \t\t\t\t\t  met_key:\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_average_per_class_acc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m        \t\t\t\t\tsplit:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masl100\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \t\t\t\t\t  footnotes:\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     64\u001b[0m \t\t\t\t\t  precision:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m'''res_dict1 - res_dict2 (e.g. flipped - orig)'''\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \tdiffs \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_diffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dict1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_dict2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmet_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m gen_single_split_table(\n\u001b[1;32m     69\u001b[0m \t\tsplit_dict\u001b[38;5;241m=\u001b[39mdiffs[split],\n\u001b[1;32m     70\u001b[0m \t\tmet_key\u001b[38;5;241m=\u001b[39mmet_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \t\tprecision\u001b[38;5;241m=\u001b[39mprecision\n\u001b[1;32m     75\u001b[0m \t)\n",
      "File \u001b[0;32m~/ExtraStorage/SLR/code/tables.py:15\u001b[0m, in \u001b[0;36mcalc_diffs\u001b[0;34m(res_dict1, res_dict2, met_key)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m res_dict1[split]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     13\u001b[0m \tres[split][arch] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 15\u001b[0m \ttopk1 \u001b[38;5;241m=\u001b[39m \u001b[43mres_dict1\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43march\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmet_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \ttopk2 \u001b[38;5;241m=\u001b[39m res_dict2[split][arch][met_key]\n\u001b[1;32m     17\u001b[0m \ttopkeys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop10\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from tables import gen_compare_table\n",
    "\n",
    "print(gen_compare_table(\n",
    "    sum16['asl100'],\n",
    "    sum32['asl100'],\n",
    "    caption='Comparison of 16 and 32 frame 3D CNN results on WLASL100', \n",
    "    label='tab:wlasl_16f_vs_32f',\n",
    "    footnotes=[\n",
    "        '32 - 16 frame difference',\n",
    "        'All models use 16 or 32 frames as input respectively.'\n",
    "    ]       \n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlasl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

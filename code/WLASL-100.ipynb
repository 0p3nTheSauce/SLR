{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e017a9d2",
   "metadata": {},
   "source": [
    "# Comparing 3D CNN, and Vision Transformer feature extractors for Isolated Sign Language Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061ac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import test\n",
    "import configs\n",
    "from torchvision.transforms import v2\n",
    "from video_dataset import VideoDataset\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from models import pytorch_mvit, pytorch_r3d, pytorch_s3d, pytorch_swin3d\n",
    "import json\n",
    "import utils\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  \n",
    "set_seed()\n",
    "\n",
    "with open('wlasl_implemented_info.json', 'r') as f:\n",
    "  imp_info = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac83f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asl100', 'asl300']\n",
      "dict_keys(['MViT_V1_B', 'MViT_V2_S', 'Swin3D_B', 'Swin3D_S', 'Swin3D_T', 'Resnet2D_1D_18', 'Resnet3D_18', 'S3D'])\n"
     ]
    }
   ],
   "source": [
    "print(imp_info['splits'])\n",
    "print(imp_info['models'].keys())\n",
    "model_info = imp_info['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec76f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'asl100'\n",
    "root = Path('../data/WLASL/WLASL2000')\n",
    "labels = Path(f'./preprocessed/labels/{split}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcb42b",
   "metadata": {},
   "source": [
    "## Resnet3D_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_no = '004' #chosen based on wandb dashboard\n",
    "model = 'Resnet3D_18'\n",
    "config_path = Path(f'configfiles/{split}/{model}_{exp_no}.ini')\n",
    "output = Path(f'runs/{split}/{model}_exp{exp_no}')\n",
    "save_path = output / 'checkpoints'\n",
    "arg_dict = {\n",
    "  'model' : model,\n",
    "  'exp_no': exp_no,\n",
    "  'split' : split,\n",
    "  'root' : root,\n",
    "  'labels' : labels,\n",
    "  'save_path' : save_path,\n",
    "  'config_path' : config_path \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dabcfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING:\n",
      "    batch_size            : 2\n",
      "    update_per_step       : 4\n",
      "    max_epoch             : 200\n",
      "    early_stopping        : {'metric': ('val', 'loss'), 'mode': 'min', 'patience': 50, 'min_delta': 0.01}\n",
      "    batch_size_equivalent : 8\n",
      "\n",
      "OPTIMIZER:\n",
      "    eps                     : 0.001\n",
      "    backbone_init_lr        : 1e-05\n",
      "    backbone_weight_decay   : 0.0001\n",
      "    classifier_init_lr      : 0.001\n",
      "    classifier_weight_decay : 1e-07\n",
      "\n",
      "MODEL_PARAMS:\n",
      "    drop_p : 0.5\n",
      "\n",
      "SCHEDULER:\n",
      "    tmax    : 100\n",
      "    eta_min : 1e-05\n",
      "\n",
      "DATA:\n",
      "    num_frames : 32\n",
      "    frame_size : 224\n",
      "\n",
      "ADMIN:\n",
      "    config_path : configfiles/asl100/Resnet3D_18_004.ini\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = configs.load_config({'config_path':config_path})\n",
    "configs.print_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76677e",
   "metadata": {},
   "source": [
    "### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b772997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "idx : 6\n",
      "mean : [0.43216, 0.394666, 0.37645]\n",
      "std : [0.22803, 0.22145, 0.216989]\n",
      "}\n",
      "\n",
      "258\n",
      "258\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "resnet_info = model_info[model]\n",
    "utils.print_dict(resnet_info)\n",
    "mean = resnet_info['mean']\n",
    "std = resnet_info['std']\n",
    "\n",
    "r3d18_final = v2.Compose([\n",
    "  v2.Lambda(lambda x: x.float() / 255.0),\n",
    "  v2.Normalize(mean=mean, std=std),\n",
    "  v2.Lambda(lambda x: x.permute(1,0,2,3)) \n",
    "])\n",
    "\n",
    "train_transforms = v2.Compose([v2.RandomCrop(config['data']['frame_size']),\n",
    "                                 v2.RandomHorizontalFlip(),\n",
    "                                 r3d18_final])\n",
    "test_transforms = v2.Compose([v2.CenterCrop(config['data']['frame_size']),\n",
    "                                r3d18_final])\n",
    "\n",
    "test_instances = labels / 'test_instances_fixed_frange_bboxes_len.json'\n",
    "test_classes = labels / 'test_classes_fixed_frange_bboxes_len.json'\n",
    "\n",
    "test_set = VideoDataset(root, test_instances, test_classes,\n",
    "    transforms=test_transforms, num_frames=config['data']['num_frames'])\n",
    "test_loader = DataLoader(test_set,\n",
    "    batch_size=1, shuffle=True, num_workers=2,pin_memory=False, drop_last=False)\n",
    "num_classes = len(set(test_set.classes))\n",
    "print(len(test_set))\n",
    "# print(len(test_loader))\n",
    "print(num_classes)\n",
    "# print(len(set(test_loader.dataset.classes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2119a1",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ddc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/asl100/Resnet3D_18_exp004/checkpoints/checkpoint_117.pth\n"
     ]
    }
   ],
   "source": [
    "#unfortunately, i believe the best weights may not have saved correctly\n",
    "#using the last available weights\n",
    "checkpoint_path = next(save_path.iterdir())\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b26fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3d18 = pytorch_r3d.Resnet3D_18_basic(\n",
    "  num_classes=num_classes,\n",
    "  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlasl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89ceb0a",
   "metadata": {},
   "source": [
    "# The best performing model so far on asl100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a7497c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import test\n",
    "from configs import Config\n",
    "from torchvision.transforms import v2\n",
    "from video_dataset import VideoDataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from models.pytorch_r3d import Resnet3D18_basic\n",
    "import json\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03c45419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testting r3d18 on split asl100 \n",
      "              Experiment no: 006 \n",
      "              Raw videos at: ../data/WLASL2000\n",
      "              Labels at: ./preprocessed/labels/asl100\n",
      "              Saving files to: runs/asl100/r3d18_exp006\n",
      "              Model weights: best.pth\n",
      "              Config:\n",
      "\t\tModel: <class 'models.pytorch_r3d.Resnet3D18_basic'>\n",
      "\t\tWeights Path: \n",
      "\t\tFrozen layers: []\n",
      "\t\tScheduler: t_max=100, eta_min=1e-05\n",
      "\t\tTraining: bs=6, steps=64000, ups=1\n",
      "\t\tOptimizer: lr=0.001, eps=0.001, wd=1e-07\n",
      "\t\tBackbone: lr=1e-05, wd=0.0001\n",
      "\t\tClassifier: lr=0.001, wd=0.0001\n",
      "              \n",
      "\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = 'r3d18'\n",
    "split = 'asl100'\n",
    "exp_no = '6'.zfill(3)\n",
    "\n",
    "\n",
    "root = '../data/WLASL2000'\n",
    "labels=f'./preprocessed/labels/{split}'\n",
    "output=f'runs/{split}/{model}_exp{exp_no}'\n",
    "config_path = f'./configfiles/{split}/{model}_{exp_no}.ini'\n",
    "configs = Config(config_path)\n",
    "model_dict='best.pth'\n",
    "classes_path = './wlasl_class_list.json'\n",
    "label_suffix='_fixed_frange_bboxes_len.json'\n",
    "title = f'''Testting {model} on split {split} \n",
    "              Experiment no: {exp_no} \n",
    "              Raw videos at: {root}\n",
    "              Labels at: {labels}\n",
    "              Saving files to: {output}\n",
    "              Model weights: {model_dict}\n",
    "              {str(configs)}\n",
    "              \\n\n",
    "          '''\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7e958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05ba5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/ExtraStorage/WLASL/lukes-code/test.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  r3d18_dict = torch.load(os.path.join(output,'checkpoints', model_dict)) #future warning, use weights_only=True (security stuff if you dont know the file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/258 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test_r3d18_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ExtraStorage/WLASL/lukes-code/test.py:149\u001b[0m, in \u001b[0;36mrun_test_r3d18_1\u001b[0;34m(configs, root, labels, output, model_dict, verbose, save)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# batch = next(iter(test_loader))\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# data, target = batch\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# print(data.shape) #torch.Size([1, 3, 32, 224, 224])\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(test_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 149\u001b[0m   data, target, meta_info \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    150\u001b[0m   data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    152\u001b[0m   \u001b[38;5;66;03m# per_frame_logits = r3d18(data)    \u001b[39;00m\n\u001b[1;32m    153\u001b[0m   \u001b[38;5;66;03m# predictions = torch.max(per_frame_logits, dim=2)[0]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "test.run_test_r3d18_1(configs,\n",
    "                      root=root,\n",
    "                      output=output,\n",
    "                      labels=labels,\n",
    "                      model_dict=model_dict,\n",
    "                      save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72fac041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup transforms\n",
    "base_mean = [0.43216, 0.394666, 0.37645]\n",
    "base_std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "r3d18_final = v2.Compose([\n",
    "  v2.Lambda(lambda x: x.float() / 255.0),\n",
    "  # v2.Lambda(lambda x: vt.normalise(x, base_mean, base_std)),\n",
    "  v2.Normalize(mean=base_mean, std=base_std),\n",
    "  v2.Lambda(lambda x: x.permute(1,0,2,3)) \n",
    "])\n",
    "\n",
    "test_transforms = v2.Compose([v2.CenterCrop(224),\n",
    "                              r3d18_final])\n",
    "\n",
    "#setup data\n",
    "test_instances = os.path.join(labels, 'test_instances_fixed_frange_bboxes_len.json')\n",
    "test_classes = os.path.join(labels, 'test_classes_fixed_frange_bboxes_len.json')\n",
    "\n",
    "test_set = VideoDataset(root, test_instances, test_classes,\n",
    "                        transforms=test_transforms, num_frames=32)\n",
    "test_loader = DataLoader(test_set, batch_size=1,shuffle=False,\n",
    "                          num_workers=0)\n",
    "num_classes = len(set(test_set.classes))\n",
    "# print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta_info = next(iter(test_loader))\n",
    "target = meta_info['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#setup model\n",
    "r3d18 = Resnet3D18_basic(num_classes=num_classes, drop_p=configs.drop_p,)\n",
    "r3d18_dict = torch.load(os.path.join(output,'checkpoints', model_dict)) #future warning, use weights_only=True (security stuff if you dont know the file)\n",
    "# print(r3d18_dict)\n",
    "r3d18.load_state_dict(r3d18_dict)\n",
    "r3d18.cuda()\n",
    "r3d18.eval()\n",
    "\n",
    "accuracy, class_report = test.test_model(r3d18, test_loader)\n",
    "print(f'Accuracy score: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot_heatmap(class_report, classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot_bar_graph(class_report, classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc9327",
   "metadata": {},
   "source": [
    "## Whats weird is that the classes can almost be split into distinct difficulty groups\n",
    "\n",
    "The model seems to have fully learned some signs, while completely failing to learn others. The rest have stagering degrees of recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb7905",
   "metadata": {},
   "source": [
    "### Lets see if we can visualise what it sees for the sign 'thursday'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thursday\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(classes_path, 'r') as f:\n",
    "  class_list = json.load(f)\n",
    "print(class_list[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['right', 'same', 'same', 'same', 'son', 'son', 'tell', 'tell', 'thursday', 'thursday']\n"
     ]
    }
   ],
   "source": [
    "print(test_set.classes[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02092879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b93d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = test_set.data[256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(dic):\n",
    "  print(\"{\")\n",
    "  for key, value in dic.items():\n",
    "    print(f\"'{key}': {value}\")\n",
    "  print(\"}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 46\n",
      "'frame_start': 1\n",
      "'video_id': 58359\n",
      "'bbox': [51, 41, 212, 222]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frames= test_set.__manual_load__(item)\n",
    "print_dict(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d75677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))\n",
    "print(type(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93975d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames)\n",
    "# utils.visualise_frames(frames, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18845e7e",
   "metadata": {},
   "source": [
    "### Honestly quite difficult, let's look at another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ee042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 92\n",
      "'frame_start': 0\n",
      "'video_id': 70026\n",
      "'bbox': [61, 30, 199, 235]\n",
      "}\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "item1 = test_set.data[257]\n",
    "frames1= test_set.__manual_load__(item1)\n",
    "print_dict(item1)\n",
    "print(len(frames1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468eba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_num': 99, 'frame_end': 46, 'frame_start': 1, 'video_id': '58359', 'bbox': [51, 41, 212, 222]}\n"
     ]
    }
   ],
   "source": [
    "print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965c080",
   "metadata": {},
   "source": [
    "### Let's gander at the originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c53e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "../data/WLASL2000/58359.mp4\n"
     ]
    }
   ],
   "source": [
    "vid_path = os.path.join(root, f\"{item['video_id']}.mp4\")\n",
    "frames_o = utils.load_rgb_frames_from_video(vid_path, item['frame_start'],\n",
    "                                          item['frame_end'])\n",
    "print(len(frames_o))\n",
    "print(vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fad379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "../data/WLASL2000/70026.mp4\n"
     ]
    }
   ],
   "source": [
    "vid_path1 = os.path.join(root, f\"{item1['video_id']}.mp4\")\n",
    "frames_o1 = utils.load_rgb_frames_from_video(vid_path1, item1['frame_start'],\n",
    "                                          item1['frame_end'])\n",
    "print(len(frames_o1))\n",
    "print(vid_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames_o1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a4284",
   "metadata": {},
   "source": [
    "### Okay cool they are not being distorted too much through loading, lets see after transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11677c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "frames_t = test_transforms(frames)\n",
    "frames_t = frames_t.permute(1,0,2,3) #just reuturn back to T C H W\n",
    "frames_t = (frames_t * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "print(frames_t.dtype)\n",
    "print(frames_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c01ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "frames_t1 = test_transforms(frames1)\n",
    "frames_t1 = frames_t1.permute(1,0,2,3) #just reuturn back to T C H W\n",
    "frames_t1 = (frames_t1 * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "print(frames_t1.dtype)\n",
    "print(frames_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53125fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.watch_video(frames_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633e2a4",
   "metadata": {},
   "source": [
    "### Normalising seems to have quite a significant effect on the videos appearence, but stil decernable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a522d",
   "metadata": {},
   "source": [
    "## Let's view some samples of this class from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms, test_transforms = configs.get_transforms()\n",
    "  \n",
    "train_instances = os.path.join(labels, f'train_instances{label_suffix}')\n",
    "train_classes = os.path.join(labels, f'train_classes{label_suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "dataset = VideoDataset(root,train_instances, train_classes,\n",
    "    transforms=train_transforms, num_frames=configs.num_frames)\n",
    "dataloader = DataLoader(dataset, batch_size=1,\n",
    "  shuffle=False, num_workers=0,pin_memory=False)\n",
    "print(len(dataset))\n",
    "num_classes = len(set(dataset.classes))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday', 'thursday']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes[-13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 74\n",
      "'frame_start': 1\n",
      "'video_id': 58361\n",
      "'bbox': [65, 24, 191, 237]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 71\n",
      "'frame_start': 1\n",
      "'video_id': 58360\n",
      "'bbox': [45, 40, 205, 220]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 55\n",
      "'frame_start': 1\n",
      "'video_id': 58369\n",
      "'bbox': [52, 37, 198, 225]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 43\n",
      "'frame_start': 1\n",
      "'video_id': 67306\n",
      "'bbox': [54, 33, 200, 228]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 58\n",
      "'frame_start': 1\n",
      "'video_id': 66640\n",
      "'bbox': [43, 40, 210, 220]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 64\n",
      "'frame_start': 1\n",
      "'video_id': 66639\n",
      "'bbox': [42, 39, 210, 219]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 77\n",
      "'frame_start': 1\n",
      "'video_id': 66638\n",
      "'bbox': [51, 34, 204, 226]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 72\n",
      "'frame_start': 1\n",
      "'video_id': 66637\n",
      "'bbox': [49, 35, 205, 223]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 49\n",
      "'frame_start': 1\n",
      "'video_id': 58367\n",
      "'bbox': [44, 28, 210, 255]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 33\n",
      "'frame_start': 1\n",
      "'video_id': 58366\n",
      "'bbox': [53, 30, 202, 255]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 38\n",
      "'frame_start': 1\n",
      "'video_id': 58364\n",
      "'bbox': [41, 45, 214, 217]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 58\n",
      "'frame_start': 1\n",
      "'video_id': 58363\n",
      "'bbox': [42, 34, 206, 224]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 50\n",
      "'frame_start': 1\n",
      "'video_id': 58362\n",
      "'bbox': [51, 26, 206, 230]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "titems = [dataset.data[i] for i in range(-1, -14, -1)]\n",
    "\n",
    "for itm in titems:\n",
    "  print_dict(itm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "for itm in titems:\n",
    "  tframes = dataset.__manual_load__(itm)\n",
    "  utils.watch_video(tframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with transforms\n",
    "for itm in titems:\n",
    "  tframes = dataset.__manual_load__(itm)\n",
    "  tframes = test_transforms(tframes)\n",
    "  tframes = tframes.permute(1,0,2,3) #just reuturn back to T C H W\n",
    "  tframes = (tframes * 255).clamp(0, 255).to(torch.uint8)\n",
    "  utils.watch_video(tframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with training transforms\n",
    "for i in range(-1, -14, -1):\n",
    "  tframes, _ = dataset.__getitem__(i)\n",
    "  tframes = tframes.permute(1,0,2,3) #just reuturn back to T C H W\n",
    "  tframes = (tframes * 255).clamp(0, 255).to(torch.uint8)\n",
    "  utils.watch_video(tframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f37401",
   "metadata": {},
   "source": [
    "### This does at least make me think I should be trying the effect of colour jitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fad357",
   "metadata": {},
   "source": [
    "## Let's see what our model thinks these are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c14a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 46\n",
      "'frame_start': 1\n",
      "'video_id': 58359\n",
      "'bbox': [51, 41, 212, 222]\n",
      "}\n",
      "{\n",
      "'label_num': 99\n",
      "'frame_end': 92\n",
      "'frame_start': 0\n",
      "'video_id': 70026\n",
      "'bbox': [61, 30, 199, 235]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_dict(item)\n",
    "print_dict(item1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, target = test_set.__getitem__(256)\n",
    "frames1, target1 = test_set.__getitem__(257)\n",
    "out = r3d18(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlasl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

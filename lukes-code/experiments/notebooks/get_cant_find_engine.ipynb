{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3428b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "cuDNN version: 90101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a279a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System Info ===\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "cuDNN version: 90101\n",
      "GPU count: 1\n",
      "Current GPU: 0\n",
      "GPU name: NVIDIA GeForce GTX 1080 Ti\n",
      "\n",
      "=== Test 1: Simple Conv3d ===\n",
      "Using device: cuda\n",
      "✓ Simple Conv3d test passed! Output shape: torch.Size([1, 64, 8, 112, 112])\n",
      "\n",
      "=== Test 2: R3D18 Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/miniconda3/envs/wlasl/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/luke/miniconda3/envs/wlasl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ R3D18 test passed! Output shape: torch.Size([1, 400])\n",
      "\n",
      "=== Test 3: CPU Fallback ===\n",
      "✓ CPU test passed! Output shape: torch.Size([1, 400])\n",
      "→ This suggests the issue is CUDA/cuDNN specific\n",
      "\n",
      "=== Test 4: Your Exact Model Setup ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/miniconda3/envs/wlasl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Your model setup test passed! Output shape: torch.Size([2, 400])\n",
      "\n",
      "=== Recommendations ===\n",
      "If tests failed:\n",
      "1. Try: pip uninstall torch torchvision && pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
      "2. Or try: conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\n",
      "3. Check nvidia-smi and nvcc --version match your PyTorch CUDA version\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.video as video_models\n",
    "\n",
    "print(\"=== System Info ===\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\n=== Test 1: Simple Conv3d ===\")\n",
    "try:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Simple 3D conv test\n",
    "    conv3d = nn.Conv3d(3, 64, kernel_size=3, stride=1, padding=1).to(device)\n",
    "    \n",
    "    # Create a small test tensor (batch_size=1, channels=3, depth=8, height=112, width=112)\n",
    "    test_input = torch.randn(1, 3, 8, 112, 112).to(device)\n",
    "    \n",
    "    output = conv3d(test_input)\n",
    "    print(f\"✓ Simple Conv3d test passed! Output shape: {output.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Simple Conv3d test failed: {e}\")\n",
    "\n",
    "print(\"\\n=== Test 2: R3D18 Model ===\")\n",
    "try:\n",
    "    # Test the same model you're using\n",
    "    model = video_models.r3d_18(pretrained=False).to(device)\n",
    "    \n",
    "    # Same input size as your video data\n",
    "    test_input = torch.randn(1, 3, 16, 112, 112).to(device)  # Adjust based on your input size\n",
    "    \n",
    "    with torch.no_grad():  # No need for gradients in test\n",
    "        output = model(test_input)\n",
    "    \n",
    "    print(f\"✓ R3D18 test passed! Output shape: {output.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ R3D18 test failed: {e}\")\n",
    "\n",
    "print(\"\\n=== Test 3: CPU Fallback ===\")\n",
    "try:\n",
    "    # Force CPU to see if it's a CUDA-specific issue\n",
    "    device_cpu = torch.device('cpu')\n",
    "    model_cpu = video_models.r3d_18(pretrained=False).to(device_cpu)\n",
    "    test_input_cpu = torch.randn(1, 3, 16, 112, 112).to(device_cpu)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_cpu = model_cpu(test_input_cpu)\n",
    "    \n",
    "    print(f\"✓ CPU test passed! Output shape: {output_cpu.shape}\")\n",
    "    print(\"→ This suggests the issue is CUDA/cuDNN specific\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ CPU test failed: {e}\")\n",
    "    print(\"→ This suggests a deeper PyTorch installation issue\")\n",
    "\n",
    "print(\"\\n=== Test 4: Your Exact Model Setup ===\")\n",
    "try:\n",
    "    # Try to replicate your exact setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Assuming you're using r3d_18 - adjust if different\n",
    "    model = video_models.r3d_18(pretrained=True)\n",
    "    \n",
    "    # Modify for your number of classes if needed\n",
    "    # model.fc = nn.Linear(model.fc.in_features, YOUR_NUM_CLASSES)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.train()  # Set to training mode like in your code\n",
    "    \n",
    "    # Test with a batch similar to your training\n",
    "    batch_size = 2\n",
    "    test_batch = torch.randn(batch_size, 3, 16, 112, 112).to(device)\n",
    "    \n",
    "    output = model(test_batch)\n",
    "    print(f\"✓ Your model setup test passed! Output shape: {output.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Your model setup test failed: {e}\")\n",
    "\n",
    "print(\"\\n=== Recommendations ===\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"If tests failed:\")\n",
    "    print(\"1. Try: pip uninstall torch torchvision && pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\")\n",
    "    print(\"2. Or try: conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\")\n",
    "    print(\"3. Check nvidia-smi and nvcc --version match your PyTorch CUDA version\")\n",
    "else:\n",
    "    print(\"CUDA not available - you'll need to run on CPU or fix CUDA installation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c015bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 0.49 GB\n",
      "GPU memory cached: 0.52 GB\n"
     ]
    }
   ],
   "source": [
    "# Delete specific variables\n",
    "import gc\n",
    "\n",
    "# Then clear cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    print(f\"GPU memory cached: {torch.cuda.memory_reserved()/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e2cae",
   "metadata": {},
   "source": [
    "### other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35e9fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchaudio\n",
    "# try:\n",
    "#     import torchcodec\n",
    "#     print(\"✓ torchcodec available\")\n",
    "# except ImportError:\n",
    "#     print(\"torchcodec not installed\")\n",
    "\n",
    "# print(f\"✓ torchaudio version: {torchaudio.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff90427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version in PyTorch: 12.4\n",
      "cuDNN version: 90101\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version in PyTorch: {torch.version.cuda}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlasl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

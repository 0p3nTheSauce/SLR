{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15b516d",
   "metadata": {},
   "source": [
    "# Using Yolo to create better bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36390ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "from video_dataset import load_rgb_frames_from_video\n",
    "raw_path = \"../data/WLASL2000/\"\n",
    "instance_path = \"./preprocessed_labels/asl100/train_instances.json\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30019c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /home/luke/ExtraStorage/WLASL/lukes-code/bus.jpg: 640x480 4 persons, 1 bus, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 106.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5., 0., 0., 0., 0.], device='cuda:0')\n",
      "conf: tensor([0.9402, 0.8882, 0.8783, 0.8558, 0.6219], device='cuda:0')\n",
      "data: tensor([[3.8327e+00, 2.2936e+02, 7.9619e+02, 7.2841e+02, 9.4015e-01, 5.0000e+00],\n",
      "        [6.7102e+02, 3.9483e+02, 8.0981e+02, 8.7871e+02, 8.8822e-01, 0.0000e+00],\n",
      "        [4.7405e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02, 8.7825e-01, 0.0000e+00],\n",
      "        [2.2306e+02, 4.0869e+02, 3.4447e+02, 8.6044e+02, 8.5577e-01, 0.0000e+00],\n",
      "        [2.1726e-02, 5.5607e+02, 6.8886e+01, 8.7236e+02, 6.2192e-01, 0.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[400.0136, 478.8883, 792.3620, 499.0480],\n",
      "        [740.4135, 636.7728, 138.7925, 483.8794],\n",
      "        [143.3527, 651.8801, 191.8959, 504.6299],\n",
      "        [283.7633, 634.5622, 121.4086, 451.7472],\n",
      "        [ 34.4536, 714.2139,  68.8638, 316.2908]], device='cuda:0')\n",
      "xywhn: tensor([[0.4938, 0.4434, 0.9782, 0.4621],\n",
      "        [0.9141, 0.5896, 0.1713, 0.4480],\n",
      "        [0.1770, 0.6036, 0.2369, 0.4672],\n",
      "        [0.3503, 0.5876, 0.1499, 0.4183],\n",
      "        [0.0425, 0.6613, 0.0850, 0.2929]], device='cuda:0')\n",
      "xyxy: tensor([[3.8327e+00, 2.2936e+02, 7.9619e+02, 7.2841e+02],\n",
      "        [6.7102e+02, 3.9483e+02, 8.0981e+02, 8.7871e+02],\n",
      "        [4.7405e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02],\n",
      "        [2.2306e+02, 4.0869e+02, 3.4447e+02, 8.6044e+02],\n",
      "        [2.1726e-02, 5.5607e+02, 6.8886e+01, 8.7236e+02]], device='cuda:0')\n",
      "xyxyn: tensor([[4.7317e-03, 2.1237e-01, 9.8296e-01, 6.7446e-01],\n",
      "        [8.2842e-01, 3.6559e-01, 9.9977e-01, 8.1362e-01],\n",
      "        [5.8524e-02, 3.6997e-01, 2.9543e-01, 8.3722e-01],\n",
      "        [2.7538e-01, 3.7842e-01, 4.2527e-01, 7.9670e-01],\n",
      "        [2.6822e-05, 5.1488e-01, 8.5044e-02, 8.0774e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # results list\n",
    "\n",
    "# View results\n",
    "for r in results:\n",
    "    print(r.boxes)  # print the Boxes object containing the detection bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48cb75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.8327e+00, 2.2936e+02, 7.9619e+02, 7.2841e+02],\n",
      "        [6.7102e+02, 3.9483e+02, 8.0981e+02, 8.7871e+02],\n",
      "        [4.7405e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02],\n",
      "        [2.2306e+02, 4.0869e+02, 3.4447e+02, 8.6044e+02],\n",
      "        [2.1726e-02, 5.5607e+02, 6.8886e+01, 8.7236e+02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "result = results[0]  # Get the first result\n",
    "print(result.boxes.xyxy)  # Print the bounding boxes in xyxy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d045ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.7102e+02, 3.9483e+02, 8.0981e+02, 8.7871e+02],\n",
      "        [4.7405e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02],\n",
      "        [2.2306e+02, 4.0869e+02, 3.4447e+02, 8.6044e+02],\n",
      "        [2.1726e-02, 5.5607e+02, 6.8886e+01, 8.7236e+02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#select only bounding boxes for the class 'person'\n",
    "person_bboxes = result.boxes.xyxy[result.boxes.cls == 0]  #\n",
    "print(person_bboxes)  # Print the bounding boxes for the 'person' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be689fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 186.0. Dividing input by 255.\n",
      "0: 256x256 1 person, 0.8ms\n",
      "1: 256x256 1 person, 0.8ms\n",
      "2: 256x256 1 person, 0.8ms\n",
      "3: 256x256 1 person, 0.8ms\n",
      "4: 256x256 1 person, 0.8ms\n",
      "5: 256x256 1 person, 0.8ms\n",
      "6: 256x256 1 person, 0.8ms\n",
      "7: 256x256 1 person, 0.8ms\n",
      "8: 256x256 1 person, 0.8ms\n",
      "9: 256x256 1 person, 0.8ms\n",
      "10: 256x256 1 person, 0.8ms\n",
      "11: 256x256 1 person, 0.8ms\n",
      "12: 256x256 1 person, 0.8ms\n",
      "13: 256x256 1 person, 0.8ms\n",
      "14: 256x256 1 person, 0.8ms\n",
      "15: 256x256 1 person, 0.8ms\n",
      "16: 256x256 1 person, 0.8ms\n",
      "17: 256x256 1 person, 0.8ms\n",
      "18: 256x256 1 person, 0.8ms\n",
      "19: 256x256 1 person, 0.8ms\n",
      "20: 256x256 1 person, 0.8ms\n",
      "Speed: 0.0ms preprocess, 0.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Frame 0: tensor([[ 60.0529,  44.7802, 212.9297, 220.2935]], device='cuda:0')\n",
      "Frame 1: tensor([[ 60.2409,  44.6726, 212.7652, 220.2927]], device='cuda:0')\n",
      "Frame 2: tensor([[ 60.2409,  44.6726, 212.7652, 220.2927]], device='cuda:0')\n",
      "Frame 3: tensor([[ 60.2730,  44.6530, 212.5301, 220.3191]], device='cuda:0')\n",
      "Frame 4: tensor([[ 60.3192,  44.6408, 212.4043, 220.4289]], device='cuda:0')\n",
      "Frame 5: tensor([[ 60.3192,  44.6408, 212.4043, 220.4289]], device='cuda:0')\n",
      "Frame 6: tensor([[ 60.3123,  44.6403, 212.4013, 220.4060]], device='cuda:0')\n",
      "Frame 7: tensor([[ 60.3066,  44.7746, 212.5201, 220.4088]], device='cuda:0')\n",
      "Frame 8: tensor([[ 60.3066,  44.7746, 212.5201, 220.4088]], device='cuda:0')\n",
      "Frame 9: tensor([[ 60.3079,  44.8139, 212.5156, 220.3910]], device='cuda:0')\n",
      "Frame 10: tensor([[ 60.3760,  44.8834, 212.5382, 220.3849]], device='cuda:0')\n",
      "Frame 11: tensor([[ 60.3760,  44.8834, 212.5382, 220.3849]], device='cuda:0')\n",
      "Frame 12: tensor([[ 60.4990,  44.6725, 212.9299, 220.8360]], device='cuda:0')\n",
      "Frame 13: tensor([[ 60.5829,  44.7021, 212.8857, 220.8777]], device='cuda:0')\n",
      "Frame 14: tensor([[ 60.5829,  44.7021, 212.8857, 220.8777]], device='cuda:0')\n",
      "Frame 15: tensor([[ 60.5802,  44.6471, 212.8898, 220.8391]], device='cuda:0')\n",
      "Frame 16: tensor([[ 60.6171,  44.6452, 212.8727, 220.8814]], device='cuda:0')\n",
      "Frame 17: tensor([[ 60.6171,  44.6452, 212.8727, 220.8814]], device='cuda:0')\n",
      "Frame 18: tensor([[ 60.6103,  44.6548, 212.8634, 220.8552]], device='cuda:0')\n",
      "Frame 19: tensor([[ 60.6013,  44.6729, 212.9160, 220.8575]], device='cuda:0')\n",
      "Frame 20: tensor([[ 60.6013,  44.6729, 212.9160, 220.8575]], device='cuda:0')\n",
      "Largest bounding box: [60.05291748046875, 44.6402587890625, 212.92987060546875, 220.88137817382812]\n"
     ]
    }
   ],
   "source": [
    "def get_largest_bbox(bboxes):\n",
    "  if not bboxes:\n",
    "    return None\n",
    "  x_min, y_min, x_max, y_max = bboxes[0]\n",
    "  for box in bboxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    if x1 < x_min:\n",
    "      x_min = x1\n",
    "    if y1 < y_min:\n",
    "      y_min = y1\n",
    "    if x2 > x_max:\n",
    "      x_max = x2\n",
    "    if y2 > y_max:\n",
    "      y_max = y2\n",
    "  return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "from video_dataset import load_rgb_frames_from_video\n",
    "sample = '../data/WLASL2000/00295.mp4'\n",
    "frames = load_rgb_frames_from_video(sample, 0, 100, all=True)\n",
    "frames = frames.float()  # Convert to float32\n",
    "results = model(frames, device=device)  # Run inference on the frames\n",
    "bboxes = []\n",
    "for i, result in enumerate(results):\n",
    "  print(f\"Frame {i}: {result.boxes.xyxy}\")\n",
    "  person_bboxes = result.boxes.xyxy[result.boxes.cls == 0]\n",
    "  if len(person_bboxes) > 0:\n",
    "    bboxes.extend(person_bboxes.tolist())\n",
    "# Get the largest bounding box\n",
    "largest_bbox = get_largest_bbox(bboxes)\n",
    "print(\"Largest bounding box:\", largest_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c4c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output video saved to ./output/output.mp4\n"
     ]
    }
   ],
   "source": [
    "#visualize the largest bounding box on the video, write to output file\n",
    "import cv2\n",
    "output_path = './output/output.mp4'\n",
    "#convert frames to numpy uint8\n",
    "frames = frames.permute(0, 2, 3, 1).cpu().numpy().astype('uint8')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (frames.shape[2], frames.shape[1]))\n",
    "for i, frame in enumerate(frames):\n",
    "  if largest_bbox is not None:\n",
    "    x_min, y_min, x_max, y_max = map(int, largest_bbox)\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "  out.write(frame)\n",
    "out.release()\n",
    "print(f\"Output video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92c807",
   "metadata": {},
   "source": [
    "### It seems that particular video is actually really bad\n",
    "\n",
    "goign to try with a different video, and later exclude certain videos if they are too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6776e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 186.0. Dividing input by 255.\n",
      "0: 256x256 1 person, 16.6ms\n",
      "1: 256x256 1 person, 16.6ms\n",
      "2: 256x256 1 person, 16.6ms\n",
      "3: 256x256 1 person, 16.6ms\n",
      "4: 256x256 1 person, 16.6ms\n",
      "5: 256x256 1 person, 16.6ms\n",
      "6: 256x256 1 person, 16.6ms\n",
      "7: 256x256 1 person, 16.6ms\n",
      "8: 256x256 1 person, 16.6ms\n",
      "9: 256x256 1 person, 16.6ms\n",
      "10: 256x256 1 person, 16.6ms\n",
      "11: 256x256 1 person, 16.6ms\n",
      "12: 256x256 1 person, 16.6ms\n",
      "13: 256x256 1 person, 16.6ms\n",
      "14: 256x256 1 person, 16.6ms\n",
      "15: 256x256 1 person, 16.6ms\n",
      "16: 256x256 1 person, 16.6ms\n",
      "17: 256x256 1 person, 16.6ms\n",
      "18: 256x256 1 person, 16.6ms\n",
      "19: 256x256 1 person, 16.6ms\n",
      "20: 256x256 1 person, 16.6ms\n",
      "21: 256x256 1 person, 16.6ms\n",
      "22: 256x256 1 person, 16.6ms\n",
      "23: 256x256 1 person, 16.6ms\n",
      "24: 256x256 1 person, 16.6ms\n",
      "25: 256x256 1 person, 16.6ms\n",
      "26: 256x256 1 person, 16.6ms\n",
      "27: 256x256 1 person, 16.6ms\n",
      "28: 256x256 1 person, 16.6ms\n",
      "29: 256x256 1 person, 16.6ms\n",
      "30: 256x256 1 person, 16.6ms\n",
      "31: 256x256 1 person, 16.6ms\n",
      "32: 256x256 1 person, 16.6ms\n",
      "33: 256x256 1 person, 16.6ms\n",
      "34: 256x256 1 person, 16.6ms\n",
      "35: 256x256 1 person, 16.6ms\n",
      "36: 256x256 1 person, 16.6ms\n",
      "37: 256x256 1 person, 16.6ms\n",
      "38: 256x256 1 person, 16.6ms\n",
      "39: 256x256 1 person, 16.6ms\n",
      "40: 256x256 1 person, 16.6ms\n",
      "41: 256x256 1 person, 16.6ms\n",
      "42: 256x256 1 person, 16.6ms\n",
      "43: 256x256 1 person, 16.6ms\n",
      "44: 256x256 1 person, 16.6ms\n",
      "45: 256x256 1 person, 16.6ms\n",
      "46: 256x256 1 person, 16.6ms\n",
      "47: 256x256 1 person, 16.6ms\n",
      "48: 256x256 1 person, 16.6ms\n",
      "49: 256x256 1 person, 16.6ms\n",
      "50: 256x256 1 person, 16.6ms\n",
      "51: 256x256 1 person, 16.6ms\n",
      "Speed: 0.0ms preprocess, 16.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Frame 0: tensor([[ 50.0126,  40.5830, 210.0438, 223.9305]], device='cuda:0')\n",
      "Frame 1: tensor([[ 50.8335,  40.5438, 209.6787, 223.8275]], device='cuda:0')\n",
      "Frame 2: tensor([[ 50.8986,  40.5437, 209.6537, 223.7274]], device='cuda:0')\n",
      "Frame 3: tensor([[ 50.2368,  40.5381, 209.8065, 223.5161]], device='cuda:0')\n",
      "Frame 4: tensor([[ 49.8051,  40.5235, 209.7984, 223.5665]], device='cuda:0')\n",
      "Frame 5: tensor([[ 49.8059,  40.5211, 209.7993, 223.5722]], device='cuda:0')\n",
      "Frame 6: tensor([[ 49.8003,  40.5229, 209.7991, 223.5750]], device='cuda:0')\n",
      "Frame 7: tensor([[ 49.8003,  40.5229, 209.7991, 223.5750]], device='cuda:0')\n",
      "Frame 8: tensor([[ 50.0788,  40.5407, 209.8766, 223.1675]], device='cuda:0')\n",
      "Frame 9: tensor([[ 50.0831,  40.5422, 209.8821, 223.1569]], device='cuda:0')\n",
      "Frame 10: tensor([[ 49.9256,  40.5415, 209.8926, 223.2320]], device='cuda:0')\n",
      "Frame 11: tensor([[ 49.9716,  40.5401, 209.9035, 223.1372]], device='cuda:0')\n",
      "Frame 12: tensor([[ 50.3608,  40.6373, 209.6875, 223.7296]], device='cuda:0')\n",
      "Frame 13: tensor([[ 48.3054,  40.6819, 209.5964, 223.4954]], device='cuda:0')\n",
      "Frame 14: tensor([[ 48.2044,  40.6677, 209.5991, 223.4512]], device='cuda:0')\n",
      "Frame 15: tensor([[ 48.2044,  40.6677, 209.5991, 223.4512]], device='cuda:0')\n",
      "Frame 16: tensor([[ 48.0917,  40.6565, 209.6743, 223.4372]], device='cuda:0')\n",
      "Frame 17: tensor([[ 47.9652,  40.6661, 209.6766, 223.4511]], device='cuda:0')\n",
      "Frame 18: tensor([[ 47.8605,  40.8785, 209.7600, 223.6759]], device='cuda:0')\n",
      "Frame 19: tensor([[ 47.9697,  40.8888, 209.7068, 223.7314]], device='cuda:0')\n",
      "Frame 20: tensor([[ 47.9641,  40.8904, 209.7099, 223.7172]], device='cuda:0')\n",
      "Frame 21: tensor([[ 48.0269,  41.0565, 209.7146, 223.6723]], device='cuda:0')\n",
      "Frame 22: tensor([[ 48.0483,  41.0660, 209.7198, 223.6560]], device='cuda:0')\n",
      "Frame 23: tensor([[ 48.0483,  41.0660, 209.7198, 223.6560]], device='cuda:0')\n",
      "Frame 24: tensor([[ 47.4999,  40.5822, 209.6973, 223.6628]], device='cuda:0')\n",
      "Frame 25: tensor([[ 47.4953,  40.5971, 209.6725, 223.6987]], device='cuda:0')\n",
      "Frame 26: tensor([[ 47.4966,  40.5992, 209.6970, 223.6910]], device='cuda:0')\n",
      "Frame 27: tensor([[ 47.2347,  40.6362, 209.6707, 223.4566]], device='cuda:0')\n",
      "Frame 28: tensor([[ 47.2560,  40.6647, 209.6612, 223.4211]], device='cuda:0')\n",
      "Frame 29: tensor([[ 47.2944,  40.6499, 209.6113, 223.6355]], device='cuda:0')\n",
      "Frame 30: tensor([[ 47.3218,  40.6479, 209.6216, 223.6458]], device='cuda:0')\n",
      "Frame 31: tensor([[ 47.3217,  40.6469, 209.6221, 223.6462]], device='cuda:0')\n",
      "Frame 32: tensor([[ 47.3217,  40.6469, 209.6221, 223.6462]], device='cuda:0')\n",
      "Frame 33: tensor([[ 47.2787,  40.7005, 209.6207, 223.5415]], device='cuda:0')\n",
      "Frame 34: tensor([[ 47.2852,  40.6680, 209.6192, 223.5363]], device='cuda:0')\n",
      "Frame 35: tensor([[ 47.2578,  40.6636, 209.5971, 223.4185]], device='cuda:0')\n",
      "Frame 36: tensor([[ 48.1384,  41.0405, 209.7169, 223.3384]], device='cuda:0')\n",
      "Frame 37: tensor([[ 48.1248,  41.0630, 209.7529, 223.3641]], device='cuda:0')\n",
      "Frame 38: tensor([[ 48.0936,  41.0670, 209.7728, 223.4160]], device='cuda:0')\n",
      "Frame 39: tensor([[ 48.0963,  41.0697, 209.7753, 223.3898]], device='cuda:0')\n",
      "Frame 40: tensor([[ 48.0963,  41.0697, 209.7753, 223.3898]], device='cuda:0')\n",
      "Frame 41: tensor([[ 48.1028,  41.0679, 209.8001, 223.3847]], device='cuda:0')\n",
      "Frame 42: tensor([[ 48.0933,  41.0673, 209.8013, 223.3903]], device='cuda:0')\n",
      "Frame 43: tensor([[ 48.1280,  41.0516, 209.7747, 223.4254]], device='cuda:0')\n",
      "Frame 44: tensor([[ 48.1303,  41.0349, 209.7756, 223.4241]], device='cuda:0')\n",
      "Frame 45: tensor([[ 48.1303,  41.0349, 209.7756, 223.4241]], device='cuda:0')\n",
      "Frame 46: tensor([[ 48.1550,  41.0572, 209.7640, 223.3676]], device='cuda:0')\n",
      "Frame 47: tensor([[ 48.1556,  41.0610, 209.7656, 223.3717]], device='cuda:0')\n",
      "Frame 48: tensor([[ 48.0546,  40.9211, 210.3569, 223.0878]], device='cuda:0')\n",
      "Frame 49: tensor([[ 48.1077,  40.9283, 210.3936, 223.0920]], device='cuda:0')\n",
      "Frame 50: tensor([[ 48.1068,  40.9392, 210.3943, 223.0933]], device='cuda:0')\n",
      "Frame 51: tensor([[ 48.1068,  40.9392, 210.3943, 223.0933]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample = '../data/WLASL2000/00333.mp4'\n",
    "frames = load_rgb_frames_from_video(sample, 0, 100, all=True)\n",
    "frames = frames.float()  # Convert to float32\n",
    "results = model(frames, device=device)  # Run inference on the frames\n",
    "bboxes = []\n",
    "for i, result in enumerate(results):\n",
    "  print(f\"Frame {i}: {result.boxes.xyxy}\")\n",
    "  person_bboxes = result.boxes.xyxy[result.boxes.cls == 0]\n",
    "  if len(person_bboxes) > 0:\n",
    "    bboxes.extend(person_bboxes.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d7c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest bounding box: [47.234710693359375, 40.5211181640625, 210.39431762695312, 223.93048095703125]\n"
     ]
    }
   ],
   "source": [
    "# Get the largest bounding box\n",
    "largest_bbox = get_largest_bbox(bboxes)\n",
    "print(\"Largest bounding box:\", largest_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b6fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output video saved to ./output/output.mp4\n"
     ]
    }
   ],
   "source": [
    "frames = frames.permute(0, 2, 3, 1).cpu().numpy().astype('uint8')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (frames.shape[2], frames.shape[1]))\n",
    "for i, frame in enumerate(frames):\n",
    "  if largest_bbox is not None:\n",
    "    x_min, y_min, x_max, y_max = map(int, largest_bbox)\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "  out.write(frame)\n",
    "out.release()\n",
    "print(f\"Output video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a523d7",
   "metadata": {},
   "source": [
    "### That seems to have worked very well, testing on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c784a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 227.0. Dividing input by 255.\n",
      "0: 256x256 1 person, 4.0ms\n",
      "1: 256x256 1 person, 4.0ms\n",
      "2: 256x256 1 person, 4.0ms\n",
      "3: 256x256 1 person, 4.0ms\n",
      "4: 256x256 1 person, 4.0ms\n",
      "5: 256x256 1 person, 4.0ms\n",
      "6: 256x256 1 person, 4.0ms\n",
      "7: 256x256 1 person, 4.0ms\n",
      "8: 256x256 1 person, 4.0ms\n",
      "9: 256x256 1 person, 4.0ms\n",
      "10: 256x256 1 person, 4.0ms\n",
      "11: 256x256 1 person, 4.0ms\n",
      "12: 256x256 1 person, 4.0ms\n",
      "13: 256x256 1 person, 4.0ms\n",
      "14: 256x256 1 person, 4.0ms\n",
      "15: 256x256 1 person, 4.0ms\n",
      "16: 256x256 1 person, 4.0ms\n",
      "17: 256x256 1 person, 4.0ms\n",
      "18: 256x256 1 person, 4.0ms\n",
      "19: 256x256 1 person, 4.0ms\n",
      "20: 256x256 1 person, 4.0ms\n",
      "21: 256x256 1 person, 4.0ms\n",
      "22: 256x256 1 person, 4.0ms\n",
      "23: 256x256 1 person, 4.0ms\n",
      "24: 256x256 1 person, 4.0ms\n",
      "25: 256x256 1 person, 4.0ms\n",
      "26: 256x256 1 person, 4.0ms\n",
      "27: 256x256 1 person, 4.0ms\n",
      "28: 256x256 1 person, 4.0ms\n",
      "29: 256x256 1 person, 4.0ms\n",
      "30: 256x256 1 person, 4.0ms\n",
      "31: 256x256 1 person, 4.0ms\n",
      "32: 256x256 1 person, 4.0ms\n",
      "33: 256x256 1 person, 4.0ms\n",
      "34: 256x256 1 person, 4.0ms\n",
      "35: 256x256 1 person, 4.0ms\n",
      "36: 256x256 1 person, 4.0ms\n",
      "37: 256x256 1 person, 4.0ms\n",
      "38: 256x256 1 person, 4.0ms\n",
      "39: 256x256 1 person, 4.0ms\n",
      "40: 256x256 1 person, 4.0ms\n",
      "41: 256x256 1 person, 4.0ms\n",
      "42: 256x256 1 person, 4.0ms\n",
      "43: 256x256 1 person, 4.0ms\n",
      "44: 256x256 1 person, 4.0ms\n",
      "45: 256x256 1 person, 4.0ms\n",
      "46: 256x256 1 person, 4.0ms\n",
      "47: 256x256 1 person, 4.0ms\n",
      "48: 256x256 1 person, 4.0ms\n",
      "49: 256x256 1 person, 4.0ms\n",
      "50: 256x256 1 person, 4.0ms\n",
      "51: 256x256 1 person, 4.0ms\n",
      "52: 256x256 1 person, 4.0ms\n",
      "53: 256x256 1 person, 4.0ms\n",
      "54: 256x256 1 person, 4.0ms\n",
      "55: 256x256 1 person, 4.0ms\n",
      "56: 256x256 1 person, 4.0ms\n",
      "57: 256x256 1 person, 4.0ms\n",
      "58: 256x256 1 person, 4.0ms\n",
      "59: 256x256 1 person, 4.0ms\n",
      "60: 256x256 1 person, 4.0ms\n",
      "61: 256x256 1 person, 4.0ms\n",
      "62: 256x256 1 person, 4.0ms\n",
      "63: 256x256 1 person, 4.0ms\n",
      "64: 256x256 1 person, 4.0ms\n",
      "65: 256x256 1 person, 4.0ms\n",
      "66: 256x256 1 person, 4.0ms\n",
      "67: 256x256 1 person, 4.0ms\n",
      "68: 256x256 1 person, 4.0ms\n",
      "69: 256x256 1 person, 4.0ms\n",
      "70: 256x256 1 person, 4.0ms\n",
      "71: 256x256 1 person, 4.0ms\n",
      "72: 256x256 1 person, 4.0ms\n",
      "73: 256x256 1 person, 4.0ms\n",
      "74: 256x256 1 person, 1 remote, 4.0ms\n",
      "75: 256x256 1 person, 1 remote, 4.0ms\n",
      "76: 256x256 1 person, 4.0ms\n",
      "77: 256x256 1 person, 4.0ms\n",
      "78: 256x256 1 person, 4.0ms\n",
      "79: 256x256 1 person, 4.0ms\n",
      "80: 256x256 1 person, 4.0ms\n",
      "81: 256x256 1 person, 4.0ms\n",
      "82: 256x256 1 person, 4.0ms\n",
      "83: 256x256 1 person, 4.0ms\n",
      "84: 256x256 1 person, 4.0ms\n",
      "85: 256x256 1 person, 4.0ms\n",
      "86: 256x256 1 person, 4.0ms\n",
      "87: 256x256 1 person, 4.0ms\n",
      "88: 256x256 1 person, 4.0ms\n",
      "89: 256x256 1 person, 4.0ms\n",
      "90: 256x256 1 person, 4.0ms\n",
      "91: 256x256 1 person, 4.0ms\n",
      "92: 256x256 1 person, 1 remote, 4.0ms\n",
      "93: 256x256 1 person, 1 remote, 4.0ms\n",
      "94: 256x256 1 person, 1 remote, 4.0ms\n",
      "95: 256x256 1 person, 4.0ms\n",
      "96: 256x256 1 person, 4.0ms\n",
      "97: 256x256 1 person, 4.0ms\n",
      "98: 256x256 1 person, 4.0ms\n",
      "99: 256x256 1 person, 4.0ms\n",
      "100: 256x256 1 person, 4.0ms\n",
      "101: 256x256 1 person, 4.0ms\n",
      "102: 256x256 1 person, 4.0ms\n",
      "103: 256x256 1 person, 4.0ms\n",
      "104: 256x256 1 person, 4.0ms\n",
      "105: 256x256 1 person, 4.0ms\n",
      "106: 256x256 1 person, 4.0ms\n",
      "107: 256x256 1 person, 4.0ms\n",
      "108: 256x256 1 person, 4.0ms\n",
      "109: 256x256 1 person, 4.0ms\n",
      "110: 256x256 1 person, 4.0ms\n",
      "111: 256x256 1 person, 4.0ms\n",
      "112: 256x256 1 person, 4.0ms\n",
      "113: 256x256 1 person, 4.0ms\n",
      "114: 256x256 1 person, 4.0ms\n",
      "115: 256x256 1 person, 4.0ms\n",
      "116: 256x256 1 person, 4.0ms\n",
      "117: 256x256 1 person, 4.0ms\n",
      "118: 256x256 1 person, 4.0ms\n",
      "119: 256x256 1 person, 4.0ms\n",
      "120: 256x256 1 person, 4.0ms\n",
      "121: 256x256 1 person, 4.0ms\n",
      "122: 256x256 1 person, 4.0ms\n",
      "123: 256x256 1 person, 4.0ms\n",
      "124: 256x256 1 person, 4.0ms\n",
      "125: 256x256 1 person, 4.0ms\n",
      "126: 256x256 1 person, 4.0ms\n",
      "127: 256x256 1 person, 4.0ms\n",
      "128: 256x256 1 person, 4.0ms\n",
      "129: 256x256 1 person, 4.0ms\n",
      "130: 256x256 1 person, 4.0ms\n",
      "131: 256x256 1 person, 4.0ms\n",
      "132: 256x256 1 person, 4.0ms\n",
      "133: 256x256 1 person, 4.0ms\n",
      "134: 256x256 1 person, 4.0ms\n",
      "135: 256x256 1 person, 4.0ms\n",
      "136: 256x256 1 person, 4.0ms\n",
      "137: 256x256 1 person, 4.0ms\n",
      "138: 256x256 1 person, 4.0ms\n",
      "139: 256x256 1 person, 4.0ms\n",
      "140: 256x256 1 person, 4.0ms\n",
      "141: 256x256 1 person, 4.0ms\n",
      "142: 256x256 1 person, 4.0ms\n",
      "143: 256x256 1 person, 4.0ms\n",
      "144: 256x256 1 person, 4.0ms\n",
      "145: 256x256 1 person, 4.0ms\n",
      "146: 256x256 1 person, 4.0ms\n",
      "147: 256x256 1 person, 4.0ms\n",
      "148: 256x256 1 person, 4.0ms\n",
      "149: 256x256 1 person, 4.0ms\n",
      "150: 256x256 1 person, 4.0ms\n",
      "151: 256x256 1 person, 4.0ms\n",
      "152: 256x256 1 person, 4.0ms\n",
      "153: 256x256 1 person, 4.0ms\n",
      "154: 256x256 1 person, 4.0ms\n",
      "155: 256x256 1 person, 4.0ms\n",
      "156: 256x256 1 person, 4.0ms\n",
      "157: 256x256 1 person, 4.0ms\n",
      "158: 256x256 1 person, 4.0ms\n",
      "159: 256x256 1 person, 4.0ms\n",
      "160: 256x256 1 person, 4.0ms\n",
      "161: 256x256 1 person, 4.0ms\n",
      "162: 256x256 1 person, 4.0ms\n",
      "163: 256x256 1 person, 4.0ms\n",
      "164: 256x256 1 person, 4.0ms\n",
      "165: 256x256 1 person, 4.0ms\n",
      "166: 256x256 1 person, 4.0ms\n",
      "167: 256x256 1 person, 4.0ms\n",
      "168: 256x256 1 person, 4.0ms\n",
      "169: 256x256 1 person, 4.0ms\n",
      "170: 256x256 1 person, 4.0ms\n",
      "171: 256x256 1 person, 4.0ms\n",
      "172: 256x256 1 person, 4.0ms\n",
      "173: 256x256 1 person, 4.0ms\n",
      "174: 256x256 1 person, 4.0ms\n",
      "175: 256x256 1 person, 4.0ms\n",
      "176: 256x256 1 person, 4.0ms\n",
      "177: 256x256 1 person, 4.0ms\n",
      "178: 256x256 1 person, 4.0ms\n",
      "179: 256x256 1 person, 4.0ms\n",
      "180: 256x256 1 person, 4.0ms\n",
      "181: 256x256 1 person, 4.0ms\n",
      "182: 256x256 1 person, 4.0ms\n",
      "183: 256x256 1 person, 4.0ms\n",
      "184: 256x256 1 person, 4.0ms\n",
      "185: 256x256 1 person, 4.0ms\n",
      "186: 256x256 1 person, 4.0ms\n",
      "187: 256x256 1 person, 4.0ms\n",
      "188: 256x256 1 person, 4.0ms\n",
      "189: 256x256 1 person, 4.0ms\n",
      "190: 256x256 1 person, 4.0ms\n",
      "191: 256x256 1 person, 4.0ms\n",
      "192: 256x256 1 person, 4.0ms\n",
      "193: 256x256 1 person, 4.0ms\n",
      "194: 256x256 1 person, 4.0ms\n",
      "195: 256x256 1 person, 4.0ms\n",
      "196: 256x256 1 person, 4.0ms\n",
      "197: 256x256 1 person, 4.0ms\n",
      "198: 256x256 1 person, 4.0ms\n",
      "199: 256x256 1 person, 4.0ms\n",
      "200: 256x256 1 person, 4.0ms\n",
      "201: 256x256 1 person, 4.0ms\n",
      "202: 256x256 1 person, 4.0ms\n",
      "Speed: 0.0ms preprocess, 4.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Frame 0: tensor([[ 65.2398,  45.4666, 196.8447, 219.9925]], device='cuda:0')\n",
      "Frame 1: tensor([[ 64.4390,  45.4976, 197.1179, 220.1300]], device='cuda:0')\n",
      "Frame 2: tensor([[ 64.3730,  45.5980, 197.1431, 220.0616]], device='cuda:0')\n",
      "Frame 3: tensor([[ 63.4552,  45.5590, 197.0793, 220.1645]], device='cuda:0')\n",
      "Frame 4: tensor([[ 62.7487,  45.5420, 196.9543, 220.0660]], device='cuda:0')\n",
      "Frame 5: tensor([[ 62.7487,  45.5420, 196.9543, 220.0660]], device='cuda:0')\n",
      "Frame 6: tensor([[ 60.4560,  45.4260, 197.9932, 220.4845]], device='cuda:0')\n",
      "Frame 7: tensor([[ 59.3852,  45.3795, 198.0928, 219.8685]], device='cuda:0')\n",
      "Frame 8: tensor([[ 59.3852,  45.3795, 198.0928, 219.8685]], device='cuda:0')\n",
      "Frame 9: tensor([[ 60.1088,  45.4259, 199.5742, 220.6429]], device='cuda:0')\n",
      "Frame 10: tensor([[ 60.3723,  45.4187, 199.5226, 221.4193]], device='cuda:0')\n",
      "Frame 11: tensor([[ 60.3723,  45.4187, 199.5226, 221.4193]], device='cuda:0')\n",
      "Frame 12: tensor([[ 64.1084,  45.3835, 200.6047, 222.8837]], device='cuda:0')\n",
      "Frame 13: tensor([[ 64.1110,  45.3867, 200.5321, 222.8747]], device='cuda:0')\n",
      "Frame 14: tensor([[ 65.2886,  45.3814, 202.2565, 222.3269]], device='cuda:0')\n",
      "Frame 15: tensor([[ 66.6044,  45.4206, 204.6668, 222.1197]], device='cuda:0')\n",
      "Frame 16: tensor([[ 67.9740,  45.4644, 204.0428, 221.8973]], device='cuda:0')\n",
      "Frame 17: tensor([[ 67.9740,  45.4644, 204.0428, 221.8973]], device='cuda:0')\n",
      "Frame 18: tensor([[ 68.3869,  45.4191, 204.0194, 222.0603]], device='cuda:0')\n",
      "Frame 19: tensor([[ 67.1395,  45.1083, 204.9040, 221.6611]], device='cuda:0')\n",
      "Frame 20: tensor([[ 67.2087,  45.3135, 206.5067, 221.6159]], device='cuda:0')\n",
      "Frame 21: tensor([[ 67.2087,  45.3135, 206.5067, 221.6159]], device='cuda:0')\n",
      "Frame 22: tensor([[ 64.0033,  45.5254, 208.6419, 222.6049]], device='cuda:0')\n",
      "Frame 23: tensor([[ 62.5301,  45.5230, 207.5744, 222.2932]], device='cuda:0')\n",
      "Frame 24: tensor([[ 59.3691,  45.0985, 207.3895, 222.2421]], device='cuda:0')\n",
      "Frame 25: tensor([[ 58.1649,  45.1181, 206.5741, 222.1278]], device='cuda:0')\n",
      "Frame 26: tensor([[ 55.6794,  45.1570, 203.9474, 221.6783]], device='cuda:0')\n",
      "Frame 27: tensor([[ 54.0580,  45.0910, 202.5645, 221.9716]], device='cuda:0')\n",
      "Frame 28: tensor([[ 51.7412,  45.2400, 201.0970, 221.7935]], device='cuda:0')\n",
      "Frame 29: tensor([[ 50.7780,  45.4376, 200.6662, 222.0430]], device='cuda:0')\n",
      "Frame 30: tensor([[ 50.1159,  45.4222, 198.9250, 221.7691]], device='cuda:0')\n",
      "Frame 31: tensor([[ 48.4174,  44.6646, 199.5069, 221.5141]], device='cuda:0')\n",
      "Frame 32: tensor([[ 47.4973,  45.4182, 198.2007, 221.4285]], device='cuda:0')\n",
      "Frame 33: tensor([[ 48.3483,  45.5692, 198.0798, 222.0500]], device='cuda:0')\n",
      "Frame 34: tensor([[ 48.7911,  45.1183, 198.2627, 220.9886]], device='cuda:0')\n",
      "Frame 35: tensor([[ 49.4279,  45.6072, 198.0642, 221.2639]], device='cuda:0')\n",
      "Frame 36: tensor([[ 49.6116,  45.5032, 197.2094, 221.8034]], device='cuda:0')\n",
      "Frame 37: tensor([[ 49.2047,  45.6513, 196.6177, 221.6993]], device='cuda:0')\n",
      "Frame 38: tensor([[ 49.2306,  45.6476, 196.6870, 221.6216]], device='cuda:0')\n",
      "Frame 39: tensor([[ 49.3758,  45.5955, 196.4239, 222.2443]], device='cuda:0')\n",
      "Frame 40: tensor([[ 49.1882,  45.5028, 196.5193, 221.8378]], device='cuda:0')\n",
      "Frame 41: tensor([[ 48.9745,  45.4884, 195.9979, 221.6888]], device='cuda:0')\n",
      "Frame 42: tensor([[ 48.9489,  45.5818, 196.4267, 221.6282]], device='cuda:0')\n",
      "Frame 43: tensor([[ 48.8986,  45.5858, 195.4651, 221.9947]], device='cuda:0')\n",
      "Frame 44: tensor([[ 48.5760,  45.6038, 195.3860, 221.5873]], device='cuda:0')\n",
      "Frame 45: tensor([[ 48.6508,  45.4592, 195.1177, 221.5210]], device='cuda:0')\n",
      "Frame 46: tensor([[ 48.6438,  45.3518, 195.3900, 221.3123]], device='cuda:0')\n",
      "Frame 47: tensor([[ 48.8970,  45.4328, 196.1111, 221.6230]], device='cuda:0')\n",
      "Frame 48: tensor([[ 49.5282,  45.3367, 195.6517, 221.2030]], device='cuda:0')\n",
      "Frame 49: tensor([[ 49.6183,  45.4673, 196.4746, 221.3091]], device='cuda:0')\n",
      "Frame 50: tensor([[ 49.7833,  45.3599, 197.6969, 221.7113]], device='cuda:0')\n",
      "Frame 51: tensor([[ 49.6903,  45.6955, 198.8225, 221.6957]], device='cuda:0')\n",
      "Frame 52: tensor([[ 50.7404,  45.7256, 199.9427, 222.0771]], device='cuda:0')\n",
      "Frame 53: tensor([[ 51.5992,  45.6965, 201.6211, 222.3367]], device='cuda:0')\n",
      "Frame 54: tensor([[ 51.8290,  45.9443, 201.3274, 221.8065]], device='cuda:0')\n",
      "Frame 55: tensor([[ 53.1965,  45.6523, 201.3528, 221.0846]], device='cuda:0')\n",
      "Frame 56: tensor([[ 54.5867,  45.7757, 200.9657, 220.6075]], device='cuda:0')\n",
      "Frame 57: tensor([[ 55.5586,  45.7844, 200.4607, 220.5419]], device='cuda:0')\n",
      "Frame 58: tensor([[ 55.8123,  45.8001, 199.7915, 220.4833]], device='cuda:0')\n",
      "Frame 59: tensor([[ 55.1158,  45.6848, 198.9987, 220.6508]], device='cuda:0')\n",
      "Frame 60: tensor([[ 55.4493,  46.0520, 198.4609, 221.4393]], device='cuda:0')\n",
      "Frame 61: tensor([[ 54.4799,  46.2426, 198.1870, 221.2182]], device='cuda:0')\n",
      "Frame 62: tensor([[ 53.3246,  46.0436, 197.9925, 220.8195]], device='cuda:0')\n",
      "Frame 63: tensor([[ 53.5175,  46.0429, 197.9937, 220.8166]], device='cuda:0')\n",
      "Frame 64: tensor([[ 52.5771,  46.0215, 197.5287, 220.7907]], device='cuda:0')\n",
      "Frame 65: tensor([[ 52.2323,  46.0159, 197.6338, 220.8787]], device='cuda:0')\n",
      "Frame 66: tensor([[ 51.4641,  45.9842, 197.4691, 220.7098]], device='cuda:0')\n",
      "Frame 67: tensor([[ 51.4621,  46.0357, 197.6795, 220.5261]], device='cuda:0')\n",
      "Frame 68: tensor([[ 51.1893,  45.8938, 197.7288, 220.9175]], device='cuda:0')\n",
      "Frame 69: tensor([[ 51.1541,  45.8257, 197.8975, 220.6685]], device='cuda:0')\n",
      "Frame 70: tensor([[ 52.4963,  45.8148, 197.9169, 220.4304]], device='cuda:0')\n",
      "Frame 71: tensor([[ 52.2828,  45.8527, 198.0641, 220.6620]], device='cuda:0')\n",
      "Frame 72: tensor([[ 52.8052,  46.1519, 197.8590, 220.6726]], device='cuda:0')\n",
      "Frame 73: tensor([[ 51.4157,  46.1181, 197.8216, 220.4042]], device='cuda:0')\n",
      "Frame 74: tensor([[ 51.3103,  45.9392, 197.7040, 220.9362],\n",
      "        [ 88.9584, 128.9839, 109.2416, 161.4921]], device='cuda:0')\n",
      "Frame 75: tensor([[ 51.1361,  45.8836, 197.7295, 220.7498],\n",
      "        [ 88.9732, 128.0870, 109.3478, 161.1017]], device='cuda:0')\n",
      "Frame 76: tensor([[ 51.4044,  45.8531, 197.7305, 220.6909]], device='cuda:0')\n",
      "Frame 77: tensor([[ 51.6672,  45.8580, 197.7741, 220.7656]], device='cuda:0')\n",
      "Frame 78: tensor([[ 51.4147,  45.8571, 197.9064, 220.6136]], device='cuda:0')\n",
      "Frame 79: tensor([[ 51.7054,  45.9211, 197.8477, 220.6146]], device='cuda:0')\n",
      "Frame 80: tensor([[ 51.4382,  45.9101, 197.9029, 220.4323]], device='cuda:0')\n",
      "Frame 81: tensor([[ 51.3528,  45.9074, 197.9443, 220.4644]], device='cuda:0')\n",
      "Frame 82: tensor([[ 51.4178,  45.8804, 197.7910, 220.3741]], device='cuda:0')\n",
      "Frame 83: tensor([[ 51.2470,  45.8370, 197.7568, 220.3527]], device='cuda:0')\n",
      "Frame 84: tensor([[ 51.1491,  45.9428, 197.7498, 221.3489]], device='cuda:0')\n",
      "Frame 85: tensor([[ 51.3698,  45.9745, 197.7615, 221.1933]], device='cuda:0')\n",
      "Frame 86: tensor([[ 50.9977,  45.9402, 197.6998, 221.0696]], device='cuda:0')\n",
      "Frame 87: tensor([[ 51.3454,  45.9667, 197.6165, 221.0229]], device='cuda:0')\n",
      "Frame 88: tensor([[ 51.3453,  45.9656, 197.6120, 221.0135]], device='cuda:0')\n",
      "Frame 89: tensor([[ 51.3823,  45.9268, 197.6445, 220.9928]], device='cuda:0')\n",
      "Frame 90: tensor([[ 51.6337,  45.9965, 197.6962, 220.7357]], device='cuda:0')\n",
      "Frame 91: tensor([[ 51.9553,  45.9905, 197.7222, 220.7360]], device='cuda:0')\n",
      "Frame 92: tensor([[ 50.5497,  45.9795, 197.6809, 220.8395],\n",
      "        [ 86.2059, 129.7222, 107.5884, 164.2015]], device='cuda:0')\n",
      "Frame 93: tensor([[ 52.2882,  46.0462, 197.6165, 220.4007],\n",
      "        [ 87.5758, 131.0790, 111.2246, 162.1008]], device='cuda:0')\n",
      "Frame 94: tensor([[ 52.2252,  46.0467, 197.5293, 220.3604],\n",
      "        [ 90.2026, 133.2387, 114.6857, 161.2569]], device='cuda:0')\n",
      "Frame 95: tensor([[ 53.8525,  46.0512, 197.3862, 220.5834]], device='cuda:0')\n",
      "Frame 96: tensor([[ 54.3728,  45.9681, 197.4190, 221.5479]], device='cuda:0')\n",
      "Frame 97: tensor([[ 56.3455,  45.6590, 196.4084, 221.4301]], device='cuda:0')\n",
      "Frame 98: tensor([[ 57.1498,  45.6006, 197.2131, 221.2003]], device='cuda:0')\n",
      "Frame 99: tensor([[ 60.7366,  45.6230, 198.7733, 221.1898]], device='cuda:0')\n",
      "Frame 100: tensor([[ 62.9688,  45.6273, 200.0684, 221.3162]], device='cuda:0')\n",
      "Frame 101: tensor([[ 67.0400,  45.5206, 202.4918, 221.5177]], device='cuda:0')\n",
      "Frame 102: tensor([[ 68.8117,  45.5536, 203.8533, 221.1601]], device='cuda:0')\n",
      "Frame 103: tensor([[ 71.0375,  45.2802, 204.1660, 221.0670]], device='cuda:0')\n",
      "Frame 104: tensor([[ 71.9794,  45.1681, 203.1678, 221.1785]], device='cuda:0')\n",
      "Frame 105: tensor([[ 71.8421,  45.0657, 203.3711, 221.3290]], device='cuda:0')\n",
      "Frame 106: tensor([[ 70.9487,  45.2045, 204.5453, 221.4944]], device='cuda:0')\n",
      "Frame 107: tensor([[ 69.5680,  45.0926, 205.9769, 221.5010]], device='cuda:0')\n",
      "Frame 108: tensor([[ 68.2724,  45.6729, 202.9433, 222.1440]], device='cuda:0')\n",
      "Frame 109: tensor([[ 66.0679,  45.6503, 204.4191, 221.2465]], device='cuda:0')\n",
      "Frame 110: tensor([[ 64.6691,  45.5165, 203.1500, 221.1300]], device='cuda:0')\n",
      "Frame 111: tensor([[ 63.1194,  45.1701, 201.6353, 221.0202]], device='cuda:0')\n",
      "Frame 112: tensor([[ 61.7788,  45.2254, 201.2082, 221.7847]], device='cuda:0')\n",
      "Frame 113: tensor([[ 62.0099,  45.2217, 201.2552, 221.8105]], device='cuda:0')\n",
      "Frame 114: tensor([[ 59.9203,  45.1282, 199.7882, 221.8130]], device='cuda:0')\n",
      "Frame 115: tensor([[ 58.8890,  44.8888, 198.8499, 222.2896]], device='cuda:0')\n",
      "Frame 116: tensor([[ 57.0617,  45.0165, 197.8807, 222.8446]], device='cuda:0')\n",
      "Frame 117: tensor([[ 55.5166,  44.9958, 196.6584, 222.2420]], device='cuda:0')\n",
      "Frame 118: tensor([[ 53.8103,  45.1972, 195.2555, 222.2067]], device='cuda:0')\n",
      "Frame 119: tensor([[ 53.1283,  45.1942, 193.9766, 222.2310]], device='cuda:0')\n",
      "Frame 120: tensor([[ 50.9432,  45.4653, 192.6593, 221.8566]], device='cuda:0')\n",
      "Frame 121: tensor([[ 50.2021,  45.4608, 192.3889, 221.5761]], device='cuda:0')\n",
      "Frame 122: tensor([[ 49.2496,  45.6349, 191.9178, 221.2536]], device='cuda:0')\n",
      "Frame 123: tensor([[ 49.4116,  45.6656, 191.6809, 221.4069]], device='cuda:0')\n",
      "Frame 124: tensor([[ 49.9068,  45.6232, 191.1666, 221.5018]], device='cuda:0')\n",
      "Frame 125: tensor([[ 50.7122,  45.5570, 190.3598, 221.8310]], device='cuda:0')\n",
      "Frame 126: tensor([[ 51.2960,  45.7073, 190.8684, 221.6631]], device='cuda:0')\n",
      "Frame 127: tensor([[ 51.0254,  45.6871, 190.7810, 221.6313]], device='cuda:0')\n",
      "Frame 128: tensor([[ 51.7598,  45.7677, 190.9443, 221.7804]], device='cuda:0')\n",
      "Frame 129: tensor([[ 51.6248,  45.9002, 190.8094, 221.7497]], device='cuda:0')\n",
      "Frame 130: tensor([[ 51.6382,  45.9419, 190.8276, 221.8402]], device='cuda:0')\n",
      "Frame 131: tensor([[ 51.9423,  45.9121, 190.7831, 221.7775]], device='cuda:0')\n",
      "Frame 132: tensor([[ 50.4350,  45.6216, 190.5101, 222.1888]], device='cuda:0')\n",
      "Frame 133: tensor([[ 50.8979,  45.8317, 190.9840, 221.8834]], device='cuda:0')\n",
      "Frame 134: tensor([[ 50.7724,  45.8616, 191.0426, 221.8597]], device='cuda:0')\n",
      "Frame 135: tensor([[ 50.3396,  45.8395, 191.0044, 221.8877]], device='cuda:0')\n",
      "Frame 136: tensor([[ 50.3396,  45.8395, 191.0044, 221.8877]], device='cuda:0')\n",
      "Frame 137: tensor([[ 50.5136,  45.8540, 190.9303, 221.8249]], device='cuda:0')\n",
      "Frame 138: tensor([[ 50.6831,  45.8558, 190.9326, 221.8091]], device='cuda:0')\n",
      "Frame 139: tensor([[ 51.6402,  45.8664, 191.0149, 221.9091]], device='cuda:0')\n",
      "Frame 140: tensor([[ 51.3336,  45.9350, 191.0927, 221.7419]], device='cuda:0')\n",
      "Frame 141: tensor([[ 51.0438,  45.8606, 191.1977, 221.8303]], device='cuda:0')\n",
      "Frame 142: tensor([[ 50.9240,  45.8399, 191.2467, 221.8821]], device='cuda:0')\n",
      "Frame 143: tensor([[ 50.8972,  45.8020, 191.1814, 221.9249]], device='cuda:0')\n",
      "Frame 144: tensor([[ 49.9540,  45.7986, 190.8719, 222.3940]], device='cuda:0')\n",
      "Frame 145: tensor([[ 49.3947,  45.8295, 190.9968, 222.0367]], device='cuda:0')\n",
      "Frame 146: tensor([[ 49.5460,  45.7964, 190.9391, 221.7073]], device='cuda:0')\n",
      "Frame 147: tensor([[ 49.5205,  45.8464, 190.8460, 221.7197]], device='cuda:0')\n",
      "Frame 148: tensor([[ 49.5147,  45.8355, 190.9169, 221.8358]], device='cuda:0')\n",
      "Frame 149: tensor([[ 48.8718,  45.7839, 191.4407, 221.8401]], device='cuda:0')\n",
      "Frame 150: tensor([[ 49.5636,  45.8525, 191.9065, 221.7036]], device='cuda:0')\n",
      "Frame 151: tensor([[ 49.4923,  45.6945, 192.2708, 221.8337]], device='cuda:0')\n",
      "Frame 152: tensor([[ 48.8208,  45.7446, 192.5465, 221.8079]], device='cuda:0')\n",
      "Frame 153: tensor([[ 48.8123,  45.8291, 192.9978, 221.8431]], device='cuda:0')\n",
      "Frame 154: tensor([[ 48.1486,  45.7889, 193.6724, 221.7178]], device='cuda:0')\n",
      "Frame 155: tensor([[ 48.6868,  45.7788, 194.3936, 221.5497]], device='cuda:0')\n",
      "Frame 156: tensor([[ 49.7590,  45.6373, 195.4050, 222.6071]], device='cuda:0')\n",
      "Frame 157: tensor([[ 49.3916,  45.8236, 196.5403, 222.6489]], device='cuda:0')\n",
      "Frame 158: tensor([[ 48.4063,  45.7072, 197.9894, 222.4860]], device='cuda:0')\n",
      "Frame 159: tensor([[ 49.4542,  45.4823, 200.4412, 221.8296]], device='cuda:0')\n",
      "Frame 160: tensor([[ 48.7451,  45.6324, 200.8392, 221.3059]], device='cuda:0')\n",
      "Frame 161: tensor([[ 49.3347,  45.5026, 201.5787, 220.2920]], device='cuda:0')\n",
      "Frame 162: tensor([[ 49.5437,  45.3158, 202.8920, 220.5653]], device='cuda:0')\n",
      "Frame 163: tensor([[ 49.7531,  45.3152, 202.8912, 220.5205]], device='cuda:0')\n",
      "Frame 164: tensor([[ 50.4547,  45.1693, 203.3006, 220.9268]], device='cuda:0')\n",
      "Frame 165: tensor([[ 50.6330,  45.1882, 203.3130, 220.9088]], device='cuda:0')\n",
      "Frame 166: tensor([[ 51.8740,  45.2014, 203.1420, 220.4716]], device='cuda:0')\n",
      "Frame 167: tensor([[ 52.6085,  45.2396, 202.5996, 220.3076]], device='cuda:0')\n",
      "Frame 168: tensor([[ 53.7692,  45.5919, 202.1969, 219.7524]], device='cuda:0')\n",
      "Frame 169: tensor([[ 54.3588,  45.5556, 201.9405, 219.8259]], device='cuda:0')\n",
      "Frame 170: tensor([[ 55.4301,  45.7184, 201.5518, 219.8462]], device='cuda:0')\n",
      "Frame 171: tensor([[ 56.4520,  45.8464, 200.5427, 220.2054]], device='cuda:0')\n",
      "Frame 172: tensor([[ 57.3807,  45.9266, 199.7041, 220.2211]], device='cuda:0')\n",
      "Frame 173: tensor([[ 57.8643,  46.1776, 199.1904, 220.3848]], device='cuda:0')\n",
      "Frame 174: tensor([[ 58.5986,  46.0522, 198.7737, 220.2863]], device='cuda:0')\n",
      "Frame 175: tensor([[ 59.5818,  46.2863, 198.4433, 220.4671]], device='cuda:0')\n",
      "Frame 176: tensor([[ 60.2292,  46.3426, 198.4299, 220.4459]], device='cuda:0')\n",
      "Frame 177: tensor([[ 61.0230,  46.2625, 198.3933, 220.2087]], device='cuda:0')\n",
      "Frame 178: tensor([[ 61.0299,  46.2518, 198.3107, 220.1197]], device='cuda:0')\n",
      "Frame 179: tensor([[ 61.4872,  46.2006, 198.2397, 220.1285]], device='cuda:0')\n",
      "Frame 180: tensor([[ 62.4156,  46.1446, 198.2596, 220.8640]], device='cuda:0')\n",
      "Frame 181: tensor([[ 62.8960,  46.2104, 198.2590, 220.7281]], device='cuda:0')\n",
      "Frame 182: tensor([[ 63.2934,  46.3321, 198.2763, 220.6853]], device='cuda:0')\n",
      "Frame 183: tensor([[ 63.5590,  46.3515, 198.3168, 220.7459]], device='cuda:0')\n",
      "Frame 184: tensor([[ 63.9004,  46.4155, 198.3602, 220.6518]], device='cuda:0')\n",
      "Frame 185: tensor([[ 63.9123,  46.4127, 198.4138, 220.6814]], device='cuda:0')\n",
      "Frame 186: tensor([[ 63.7256,  46.3643, 198.3299, 220.6045]], device='cuda:0')\n",
      "Frame 187: tensor([[ 63.8607,  46.3194, 198.5475, 220.3646]], device='cuda:0')\n",
      "Frame 188: tensor([[ 63.8590,  46.3239, 198.4960, 220.3364]], device='cuda:0')\n",
      "Frame 189: tensor([[ 63.8795,  46.3169, 198.4053, 220.3102]], device='cuda:0')\n",
      "Frame 190: tensor([[ 63.9947,  46.3345, 198.4955, 220.2763]], device='cuda:0')\n",
      "Frame 191: tensor([[ 64.0368,  46.3616, 198.5167, 220.4692]], device='cuda:0')\n",
      "Frame 192: tensor([[ 63.9998,  46.2012, 198.5586, 220.2690]], device='cuda:0')\n",
      "Frame 193: tensor([[ 63.9770,  46.1732, 198.5424, 220.2441]], device='cuda:0')\n",
      "Frame 194: tensor([[ 64.0129,  46.1578, 198.5052, 220.1335]], device='cuda:0')\n",
      "Frame 195: tensor([[ 63.6365,  46.1305, 198.6135, 220.1274]], device='cuda:0')\n",
      "Frame 196: tensor([[ 63.6553,  46.2466, 198.6310, 220.1310]], device='cuda:0')\n",
      "Frame 197: tensor([[ 63.7533,  46.2601, 198.6263, 220.2288]], device='cuda:0')\n",
      "Frame 198: tensor([[ 63.0365,  46.2954, 198.5174, 220.3457]], device='cuda:0')\n",
      "Frame 199: tensor([[ 63.7538,  46.2675, 198.4568, 220.2421]], device='cuda:0')\n",
      "Frame 200: tensor([[ 63.5765,  46.2554, 198.4660, 220.0039]], device='cuda:0')\n",
      "Frame 201: tensor([[ 63.6443,  46.2381, 198.5431, 219.9635]], device='cuda:0')\n",
      "Frame 202: tensor([[ 63.6238,  46.3019, 198.4382, 219.7514]], device='cuda:0')\n",
      "Largest bounding box: [47.49729919433594, 44.66461181640625, 208.64190673828125, 222.88372802734375]\n",
      "Output video saved to ./output/output.mp4\n"
     ]
    }
   ],
   "source": [
    "sample = '../data/WLASL2000/10892.mp4'\n",
    "frames = load_rgb_frames_from_video(sample, 0, 100, all=True)\n",
    "frames = frames.float()  # Convert to float32\n",
    "results = model(frames, device=device)  # Run inference on the frames\n",
    "bboxes = []\n",
    "for i, result in enumerate(results):\n",
    "  print(f\"Frame {i}: {result.boxes.xyxy}\")\n",
    "  person_bboxes = result.boxes.xyxy[result.boxes.cls == 0]\n",
    "  if len(person_bboxes) > 0:\n",
    "    bboxes.extend(person_bboxes.tolist())\n",
    "# Get the largest bounding box\n",
    "largest_bbox = get_largest_bbox(bboxes)\n",
    "print(\"Largest bounding box:\", largest_bbox)\n",
    "frames = frames.permute(0, 2, 3, 1).cpu().numpy().astype('uint8')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (frames.shape[2], frames.shape[1]))\n",
    "for i, frame in enumerate(frames):\n",
    "  if largest_bbox is not None:\n",
    "    x_min, y_min, x_max, y_max = map(int, largest_bbox)\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "  out.write(frame)\n",
    "out.release()\n",
    "print(f\"Output video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de732fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov11.pt\")  # Load a pretrained YOLOv8 model\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "output = './output/train_instances.json'\n",
    "log = './output/bounding_box_issues.txt'\n",
    "with open(instance_path, 'r') as f:\n",
    "  instances = json.load(f)\n",
    "\n",
    "new_instances = []\n",
    "\n",
    "for instance in tqdm.tqdm(instances, desc=\"Processing instances\"):\n",
    "  vid_path = os.path.join(raw_path, instance['video_id'] + '.mp4')\n",
    "  frames = load_rgb_frames_from_video(vid_path, start=instance['frame_start'],\n",
    "                                      end=instance['frame_end'])\n",
    "  \n",
    "  # Run inference on the frames\n",
    "  results = model(frames, verbose=False, device=device)\n",
    "  \n",
    "  # Extract bounding boxes and scores\n",
    "  bboxes = []\n",
    "  for result in results:\n",
    "    for box in result.boxes:\n",
    "      bbox = box.xyxy.cpu().numpy().tolist()  # Convert to list\n",
    "      score = box.conf.cpu().item()  # Get confidence score\n",
    "      bboxes.append({'bbox': bbox, 'score': score})\n",
    "  \n",
    "  instance['bboxes'] = bboxes\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
